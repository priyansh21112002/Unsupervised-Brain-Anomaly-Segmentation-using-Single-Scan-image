{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8bb21e-eb6c-4a07-b387-9363a3e136e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Define dataset directory\n",
    "dataset_dir = r\"C:\\Users\\priya\\Documents\\DL project\\BraTS2021_00061\"\n",
    "\n",
    "# Define paths for all image types\n",
    "t1_path = os.path.join(dataset_dir, 'BraTS2021_00061_t1.nii.gz')\n",
    "t1ce_path = os.path.join(dataset_dir, 'BraTS2021_00061_t1ce.nii.gz')\n",
    "flair_path = os.path.join(dataset_dir, 'BraTS2021_00061_flair.nii.gz')\n",
    "t2_path = os.path.join(dataset_dir, 'BraTS2021_00061_t2.nii.gz')\n",
    "\n",
    "# Load all image types\n",
    "t1_img = nib.load(t1_path).get_fdata()\n",
    "t1ce_img = nib.load(t1ce_path).get_fdata()\n",
    "flair_img = nib.load(flair_path).get_fdata()\n",
    "t2_img = nib.load(t2_path).get_fdata()\n",
    "\n",
    "# Check shape (they should be the same for all modalities)\n",
    "image_shape = t1_img.shape\n",
    "\n",
    "# Set parameters for slice selection\n",
    "start_slice = 15  # Skip the first 15 slices\n",
    "end_slice = image_shape[2] - 15  # Skip the last 15 slices\n",
    "\n",
    "# Target size for resizing\n",
    "target_size = (512, 512)\n",
    "\n",
    "# Directory to save processed images\n",
    "output_dir = 'processed_images'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Initialize slice counter\n",
    "slice_counter = 1\n",
    "\n",
    "# Function to normalize and resize image slices\n",
    "def process_and_save_slice(image_slice, slice_counter):\n",
    "    # Normalize the slice to [0, 1] range\n",
    "    image_slice = (image_slice - np.min(image_slice)) / (np.max(image_slice) - np.min(image_slice))\n",
    "    \n",
    "    # Resize the image to the target size (512x512)\n",
    "    resized_image = resize(image_slice, target_size, mode='reflect', anti_aliasing=True)\n",
    "    \n",
    "    # Save the image as a .png file\n",
    "    output_path = os.path.join(output_dir, f'{slice_counter}.png')\n",
    "    plt.imsave(output_path, resized_image, cmap='gray')\n",
    "    \n",
    "    return slice_counter + 1\n",
    "\n",
    "# Process and save slices from all modalities\n",
    "for slice_idx in range(start_slice, end_slice):\n",
    "    # Get corresponding slices from each modality\n",
    "    t1_slice = t1_img[:, :, slice_idx]\n",
    "    t1ce_slice = t1ce_img[:, :, slice_idx]\n",
    "    flair_slice = flair_img[:, :, slice_idx]\n",
    "    t2_slice = t2_img[:, :, slice_idx]\n",
    "    \n",
    "    # Process and save each slice\n",
    "    slice_counter = process_and_save_slice(t1_slice, slice_counter)\n",
    "    slice_counter = process_and_save_slice(t1ce_slice, slice_counter)\n",
    "    slice_counter = process_and_save_slice(flair_slice, slice_counter)\n",
    "    slice_counter = process_and_save_slice(t2_slice, slice_counter)\n",
    "\n",
    "print(f\"Processed images saved in '{output_dir}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227844c2-3360-4fdd-847f-6b09a61ac6be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828beb5b-709a-4c08-8b89-cd4b0dac263c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b40340-a428-432e-9e40-b7311f0f0d0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab545464-cc84-448a-aa35-3276604034bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed37d93b-5356-477f-8527-830b6a5463e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Define dataset directory\n",
    "dataset_dir = r\"C:\\Users\\priya\\Documents\\DL project\\BraTS2021_00061\"\n",
    "\n",
    "# Define paths for all image types\n",
    "t1_path = os.path.join(dataset_dir, 'BraTS2021_00061_t1.nii.gz')\n",
    "#t1ce_path = os.path.join(dataset_dir, 'BraTS2021_00061_t1ce.nii.gz')\n",
    "#flair_path = os.path.join(dataset_dir, 'BraTS2021_00061_flair.nii.gz')\n",
    "#t2_path = os.path.join(dataset_dir, 'BraTS2021_00061_t2.nii.gz')\n",
    "\n",
    "# Load all image types\n",
    "t1_img = nib.load(t1_path).get_fdata()\n",
    "#t1ce_img = nib.load(t1ce_path).get_fdata()\n",
    "#flair_img = nib.load(flair_path).get_fdata()\n",
    "#t2_img = nib.load(t2_path).get_fdata()\n",
    "\n",
    "# Check shape (they should be the same for all modalities)\n",
    "image_shape = t1_img.shape\n",
    "\n",
    "# Set parameters for slice selection\n",
    "start_slice = 15  # Skip the first 15 slices\n",
    "end_slice = image_shape[2] - 15  # Skip the last 15 slices\n",
    "\n",
    "# Target size for resizing\n",
    "target_size = (512, 512)\n",
    "\n",
    "# Directory to save processed images\n",
    "output_dir = 'processed_images_t1'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Initialize slice counter\n",
    "slice_counter = 1\n",
    "\n",
    "# Function to normalize and resize image slices\n",
    "def process_and_save_slice(image_slice, slice_counter):\n",
    "    # Normalize the slice to [0, 1] range\n",
    "    image_slice = (image_slice - np.min(image_slice)) / (np.max(image_slice) - np.min(image_slice))\n",
    "    \n",
    "    # Resize the image to the target size (512x512)\n",
    "    resized_image = resize(image_slice, target_size, mode='reflect', anti_aliasing=True)\n",
    "    \n",
    "    # Save the image as a .png file\n",
    "    output_path = os.path.join(output_dir, f'{slice_counter}.png')\n",
    "    plt.imsave(output_path, resized_image, cmap='gray')\n",
    "    \n",
    "    return slice_counter + 1\n",
    "\n",
    "# Process and save slices from all modalities\n",
    "for slice_idx in range(start_slice, end_slice):\n",
    "    # Get corresponding slices from each modality\n",
    "    t1_slice = t1_img[:, :, slice_idx]\n",
    "    #t1ce_slice = t1ce_img[:, :, slice_idx]\n",
    "    #flair_slice = flair_img[:, :, slice_idx]\n",
    "    #t2_slice = t2_img[:, :, slice_idx]\n",
    "    \n",
    "    # Process and save each slice\n",
    "    slice_counter = process_and_save_slice(t1_slice, slice_counter)\n",
    "    #slice_counter = process_and_save_slice(t1ce_slice, slice_counter)\n",
    "    #slice_counter = process_and_save_slice(flair_slice, slice_counter)\n",
    "    #slice_counter = process_and_save_slice(t2_slice, slice_counter)\n",
    "\n",
    "print(f\"Processed images saved in '{output_dir}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e641a7-737f-4704-bedc-e90564ed4f13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, losses\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time  # Add time module\n",
    "from tensorflow.keras.preprocessing.image import smart_resize\n",
    "\n",
    "# Define the weighted VAE loss function\n",
    "def vae_loss(inputs, outputs, mu, log_var):\n",
    "    reconstruction_loss = tf.reduce_mean(losses.binary_crossentropy(inputs, outputs))\n",
    "    kl_loss = -0.5 * tf.reduce_mean(1 + log_var - tf.square(mu) - tf.exp(log_var))\n",
    "    return reconstruction_loss + 0.25 * kl_loss  # Weight reconstruction more heavily\n",
    "\n",
    "# Build the VAE model\n",
    "def build_vae(input_shape):\n",
    "    # Encoder\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    mu = layers.Dense(128)(x)\n",
    "    log_var = layers.Dense(128)(x)\n",
    "\n",
    "    # Sampling function\n",
    "    def sampling(args):\n",
    "        mu, log_var = args\n",
    "        batch = tf.shape(mu)[0]\n",
    "        dim = tf.shape(mu)[1]\n",
    "        epsilon = tf.random.normal(shape=(batch, dim))\n",
    "        return mu + tf.exp(0.5 * log_var) * epsilon\n",
    "\n",
    "    z = layers.Lambda(sampling)([mu, log_var])\n",
    "\n",
    "    # Decoder\n",
    "    decoder_input = layers.Input(shape=(128,))\n",
    "    x = layers.Dense(64 * 64 * 128, activation='relu')(decoder_input)\n",
    "    x = layers.Reshape((64, 64, 128))(x)\n",
    "    x = layers.Conv2DTranspose(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)\n",
    "    x = layers.Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)\n",
    "    x = layers.Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)\n",
    "    outputs = layers.Conv2DTranspose(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    encoder = Model(inputs, [z, mu, log_var], name='encoder')\n",
    "    decoder = Model(decoder_input, outputs, name='decoder')\n",
    "\n",
    "    vae_outputs = decoder(encoder(inputs)[0])\n",
    "    vae = Model(inputs, vae_outputs, name='vae')\n",
    "\n",
    "    # Add loss function\n",
    "    vae.add_loss(vae_loss(inputs, vae_outputs, encoder(inputs)[1], encoder(inputs)[2]))\n",
    "    vae.compile(optimizer='adam')\n",
    "\n",
    "    return vae, encoder, decoder\n",
    "\n",
    "# Function to load preprocessed PNG slices from your dataset directory\n",
    "def load_slices_from_png(folder_path):\n",
    "    all_slices = []\n",
    "    for filename in sorted(os.listdir(folder_path)):\n",
    "        if filename.endswith('.png'):\n",
    "            img = cv2.imread(os.path.join(folder_path, filename), cv2.IMREAD_GRAYSCALE)\n",
    "            img = img / 255.0  # Normalize to [0,1]\n",
    "            img = np.expand_dims(img, axis=-1)  # Add channel dimension (512, 512, 1)\n",
    "            all_slices.append(img)\n",
    "    return np.array(all_slices)\n",
    "\n",
    "# Function to inject anomaly into an image\n",
    "def inject_anomaly(image, window_size=200):\n",
    "    h, w = image.shape[:2]\n",
    "    # Select a random window area from the image\n",
    "    x, y = np.random.randint(0, h - window_size), np.random.randint(0, w - window_size)\n",
    "    anomaly_window = image[x:x+window_size, y:y+window_size]\n",
    "\n",
    "    # Apply contrast change and elastic deformation\n",
    "    anomaly_window = A.RandomBrightnessContrast(p=1.0, brightness_limit=(-.4,0.4), contrast_limit=(-0.6,0.6))(image=anomaly_window)[\"image\"]\n",
    "    anomaly_window = A.ElasticTransform(p=1.0, alpha=50, sigma=50)(image=anomaly_window)[\"image\"]\n",
    "\n",
    "    # Create a random mask (you can modify this to get different shapes)\n",
    "    mask = np.zeros_like(anomaly_window, dtype=np.uint8)\n",
    "    num_shapes = np.random.randint(1, 4)  # Number of shapes to create a random mask\n",
    "\n",
    "    for _ in range(num_shapes):\n",
    "        shape_type = np.random.choice(['ellipse', 'polygon'])\n",
    "        if shape_type == 'ellipse':\n",
    "            center = (np.random.randint(0, window_size), np.random.randint(0, window_size))\n",
    "            axes = (np.random.randint(10, window_size // 2), np.random.randint(10, window_size // 2))\n",
    "            angle = np.random.randint(0, 180)\n",
    "            cv2.ellipse(mask, center, axes, angle, 0, 360, (255, 255, 255), -1)\n",
    "        elif shape_type == 'polygon':\n",
    "            num_points = np.random.randint(3, 7)\n",
    "            points = np.array([[\n",
    "                (np.random.randint(0, window_size), np.random.randint(0, window_size))\n",
    "                for _ in range(num_points)\n",
    "            ]], dtype=np.int32)\n",
    "            cv2.fillPoly(mask, points, (255, 255, 255))\n",
    "\n",
    "    # Apply mask to the anomaly window\n",
    "    masked_anomaly = cv2.bitwise_and(anomaly_window, anomaly_window, mask=mask)\n",
    "\n",
    "    # Place the modified, random-shaped window back into the original image\n",
    "    anomaly_image = image.copy()\n",
    "    new_x, new_y = np.random.randint(0, h - window_size), np.random.randint(0, w - window_size)\n",
    "\n",
    "    # Insert the masked anomaly at the new location\n",
    "    window_region = anomaly_image[new_x:new_x+window_size, new_y:new_y+window_size]\n",
    "    np.copyto(window_region, masked_anomaly, where=mask.astype(bool))\n",
    "\n",
    "    return anomaly_image, masked_anomaly\n",
    "# Albumentations augmentation\n",
    "def augment_image(image):\n",
    "    # Ensure that the image is a 2D or 3D array\n",
    "    if image.ndim == 3 and image.shape[-1] == 1:\n",
    "        image = image[..., 0]  # Remove the channel if it is a grayscale image with a single channel\n",
    "\n",
    "    image = (image * 255).astype(np.uint8)  # Convert to uint8\n",
    "    transform = A.Compose([\n",
    "         A.AdvancedBlur(p=0.5),\n",
    "         A.CLAHE(p=0.5),\n",
    "         A.Downscale(p=0.5),\n",
    "         A.Emboss(p=0.5),\n",
    "         A.Equalize(p=0.5),\n",
    "        # A.FancyPCA(p=0.5),\n",
    "         A.GaussNoise(p=0.5),\n",
    "         A.RandomBrightnessContrast(p=0.5),\n",
    "        # A.CoarseDropout(p=0.5),\n",
    "        # A.PixelDropout(p=0.5)\n",
    "    ])\n",
    "    augmented = transform(image=image)\n",
    "    return augmented['image'] / 255.0\n",
    "\n",
    "# Load dataset from PNG images\n",
    "folder_path = r\"cropped\"  \n",
    "slices = load_slices_from_png(folder_path)\n",
    "\n",
    "# Resize to (512, 512) if needed\n",
    "slices = [smart_resize(slice_img, (512, 512)) for slice_img in slices]\n",
    "slices = np.array(slices)\n",
    "\n",
    "# Instantiate the VAE\n",
    "vae, encoder, decoder = build_vae(input_shape=(512, 512, 1))\n",
    "\n",
    "# Training loop\n",
    "epochs = 5000\n",
    "batch_size = 64\n",
    "\n",
    "vae.summary()\n",
    "\n",
    "for epoch in range(epochs + 1):\n",
    "    start_time = time.time()  # Start timer\n",
    "\n",
    "    for slice_img in slices:\n",
    "        original_img = slice_img.copy()  # Keep the original image\n",
    "        \n",
    "        # Inject anomaly every 10 epochs\n",
    "        if epoch % 10 == 0:\n",
    "            anomaly_img, _ = inject_anomaly(np.squeeze(slice_img))\n",
    "        else:\n",
    "            anomaly_img = slice_img\n",
    "\n",
    "        anomaly_img = np.expand_dims(np.squeeze(anomaly_img), axis=-1)  # Ensure channel dimension\n",
    "        augmented_img = augment_image(anomaly_img)\n",
    "        augmented_img = np.expand_dims(augmented_img, axis=0)  # Add batch dimension\n",
    "\n",
    "        original_img = np.expand_dims(original_img, axis=-1)\n",
    "        original_img = np.expand_dims(original_img, axis=0)\n",
    "\n",
    "        # Train the VAE on the augmented image and its reconstruction target\n",
    "        loss = vae.train_on_batch(augmented_img, original_img)\n",
    "\n",
    "    # Calculate epoch duration\n",
    "    epoch_time = time.time() - start_time\n",
    "\n",
    "    # Save model every 100 epochs\n",
    "    if epoch % 100 == 0:\n",
    "        vae.save(f'vae_model_epoch_{epoch}.h5')\n",
    "\n",
    "    # Display images and print loss every 50 epochs\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}/{epochs}, Loss: {loss:.4f}, Time: {epoch_time:.2f}s\")\n",
    "\n",
    "        # Reconstruct the image\n",
    "        reconstructed_img = vae.predict(augmented_img)\n",
    "\n",
    "        # Plot the images\n",
    "        fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "        \n",
    "        # Original image\n",
    "        axes[0].imshow(np.squeeze(original_img), cmap='gray')\n",
    "        axes[0].set_title(\"Original Image\")\n",
    "        \n",
    "        # Anomaly image\n",
    "        axes[1].imshow(np.squeeze(anomaly_img), cmap='gray')\n",
    "        axes[1].set_title(\"Anomaly Image\")\n",
    "        \n",
    "        # Augmented image\n",
    "        axes[2].imshow(np.squeeze(augmented_img), cmap='gray')\n",
    "        axes[2].set_title(\"Augmented Image\")\n",
    "        \n",
    "        # Reconstructed image\n",
    "        axes[3].imshow(np.squeeze(reconstructed_img), cmap='gray')\n",
    "        axes[3].set_title(\"Reconstructed Image\")\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa8c3a8-8dc6-4d13-8ae4-a6be0f0caacc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b497bf0-eb85-49c7-b623-3dc818e3c016",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7258477-6c7d-4c39-b2fa-c74389543ab2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6db428-2d38-419d-a34f-2cbed6c9fd6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c26961b-d2cd-4351-b9c0-d710af76351c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, losses\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time  # Add time module\n",
    "from tensorflow.keras.preprocessing.image import smart_resize\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred)\n",
    "    return 1 - (2. * intersection + 1) / (union + 1)\n",
    "\n",
    "# Define IoU loss\n",
    "def iou_loss(y_true, y_pred):\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    total = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred)\n",
    "    union = total - intersection\n",
    "    return 1 - (intersection + 1) / (union + 1)\n",
    "\n",
    "from tensorflow.keras import layers, Model\n",
    "import tensorflow as tf\n",
    "\n",
    "def build_vae(input_shape):\n",
    "    # Encoder\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "    \n",
    "    # Bottleneck layers\n",
    "    mu = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    log_var = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "\n",
    "    # Sampling function\n",
    "    def sampling(args):\n",
    "        mu, log_var = args\n",
    "        epsilon = tf.random.normal(tf.shape(mu))\n",
    "        return mu + tf.exp(0.5 * log_var) * epsilon\n",
    "\n",
    "    z = layers.Lambda(sampling)([mu, log_var])\n",
    "\n",
    "    # Decoder starts with an input placeholder for `z`\n",
    "    decoder_input = layers.Input(shape=z.shape[1:])\n",
    "    x = layers.Conv2DTranspose(256, (3, 3), activation='relu', padding='same')(decoder_input)\n",
    "    x = layers.UpSampling2D((2, 2))(x)\n",
    "    x = layers.Conv2DTranspose(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)\n",
    "    x = layers.Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)\n",
    "    x = layers.Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)\n",
    "    outputs = layers.Conv2DTranspose(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    # Build encoder and decoder models\n",
    "    encoder = Model(inputs, [z, mu, log_var], name='encoder')\n",
    "    decoder = Model(decoder_input, outputs, name='decoder')\n",
    "\n",
    "    # VAE model with connected encoder and decoder\n",
    "    vae_outputs = decoder(encoder(inputs)[0])\n",
    "    vae = Model(inputs, vae_outputs, name='bigger_vae')\n",
    "\n",
    "    # Add VAE loss and compile\n",
    "    vae.add_loss(vae_loss(inputs, vae_outputs, encoder(inputs)[1], encoder(inputs)[2]))\n",
    "    vae.compile(optimizer='adam')\n",
    "\n",
    "    return vae, encoder, decoder\n",
    "\n",
    "\n",
    "# Function to load preprocessed PNG slices from your dataset directory\n",
    "def load_slices_from_png(folder_path):\n",
    "    all_slices = []\n",
    "    for filename in sorted(os.listdir(folder_path)):\n",
    "        if filename.endswith('.png'):\n",
    "            img = cv2.imread(os.path.join(folder_path, filename), cv2.IMREAD_GRAYSCALE)\n",
    "            img = img / 255.0  # Normalize to [0,1]\n",
    "            img = np.expand_dims(img, axis=-1)  # Add channel dimension (512, 512, 1)\n",
    "            all_slices.append(img)\n",
    "    return np.array(all_slices)\n",
    "\n",
    "# Function to inject anomaly into an image\n",
    "def inject_anomaly(image, window_size=200):\n",
    "    h, w = image.shape[:2]\n",
    "    # Select a random window area from the image\n",
    "    x, y = np.random.randint(0, h - window_size), np.random.randint(0, w - window_size)\n",
    "    anomaly_window = image[x:x+window_size, y:y+window_size]\n",
    "\n",
    "    # Apply contrast change and elastic deformation\n",
    "    anomaly_window = A.RandomBrightnessContrast(p=1.0, brightness_limit=(-.4,0.4), contrast_limit=(-0.6,0.6))(image=anomaly_window)[\"image\"]\n",
    "    anomaly_window = A.ElasticTransform(p=1.0, alpha=50, sigma=50)(image=anomaly_window)[\"image\"]\n",
    "\n",
    "    # Create a random mask (you can modify this to get different shapes)\n",
    "    mask = np.zeros_like(anomaly_window, dtype=np.uint8)\n",
    "    num_shapes = np.random.randint(1, 4)  # Number of shapes to create a random mask\n",
    "\n",
    "    for _ in range(num_shapes):\n",
    "        shape_type = np.random.choice(['ellipse', 'polygon'])\n",
    "        if shape_type == 'ellipse':\n",
    "            center = (np.random.randint(0, window_size), np.random.randint(0, window_size))\n",
    "            axes = (np.random.randint(10, window_size // 2), np.random.randint(10, window_size // 2))\n",
    "            angle = np.random.randint(0, 180)\n",
    "            cv2.ellipse(mask, center, axes, angle, 0, 360, (255, 255, 255), -1)\n",
    "        elif shape_type == 'polygon':\n",
    "            num_points = np.random.randint(3, 7)\n",
    "            points = np.array([[\n",
    "                (np.random.randint(0, window_size), np.random.randint(0, window_size))\n",
    "                for _ in range(num_points)\n",
    "            ]], dtype=np.int32)\n",
    "            cv2.fillPoly(mask, points, (255, 255, 255))\n",
    "\n",
    "    # Apply mask to the anomaly window\n",
    "    masked_anomaly = cv2.bitwise_and(anomaly_window, anomaly_window, mask=mask)\n",
    "\n",
    "    # Place the modified, random-shaped window back into the original image\n",
    "    anomaly_image = image.copy()\n",
    "    new_x, new_y = np.random.randint(0, h - window_size), np.random.randint(0, w - window_size)\n",
    "\n",
    "    # Insert the masked anomaly at the new location\n",
    "    window_region = anomaly_image[new_x:new_x+window_size, new_y:new_y+window_size]\n",
    "    np.copyto(window_region, masked_anomaly, where=mask.astype(bool))\n",
    "\n",
    "    return anomaly_image, masked_anomaly\n",
    "# Albumentations augmentation\n",
    "def augment_image(image):\n",
    "    # Ensure that the image is a 2D or 3D array\n",
    "    if image.ndim == 3 and image.shape[-1] == 1:\n",
    "        image = image[..., 0]  # Remove the channel if it is a grayscale image with a single channel\n",
    "\n",
    "    image = (image * 255).astype(np.uint8)  # Convert to uint8\n",
    "    transform = A.Compose([\n",
    "         A.AdvancedBlur(p=0.5),\n",
    "         A.CLAHE(p=0.5),\n",
    "         A.Downscale(p=0.5),\n",
    "         A.Emboss(p=0.5),\n",
    "         A.Equalize(p=0.5),\n",
    "        # A.FancyPCA(p=0.5),\n",
    "         A.GaussNoise(p=0.5),\n",
    "         A.RandomBrightnessContrast(p=0.5),\n",
    "        # A.CoarseDropout(p=0.5),\n",
    "        # A.PixelDropout(p=0.5)\n",
    "    ])\n",
    "    augmented = transform(image=image)\n",
    "    return augmented['image'] / 255.0\n",
    "\n",
    "# Load dataset from PNG images\n",
    "folder_path = r\"cropped\"  \n",
    "slices = load_slices_from_png(folder_path)\n",
    "\n",
    "# Resize to (512, 512) if needed\n",
    "slices = [smart_resize(slice_img, (512, 512)) for slice_img in slices]\n",
    "slices = np.array(slices)\n",
    "\n",
    "# Instantiate the VAE\n",
    "vae, encoder, decoder = build_vae(input_shape=(512, 512, 1))\n",
    "\n",
    "# Training loop\n",
    "epochs = 5000\n",
    "batch_size = 64\n",
    "\n",
    "vae.summary()\n",
    "\n",
    "for epoch in range(epochs + 1):\n",
    "    start_time = time.time()  # Start timer\n",
    "\n",
    "    for slice_img in slices:\n",
    "        original_img = slice_img.copy()  # Keep the original image\n",
    "        \n",
    "        # Inject anomaly every 10 epochs\n",
    "        if epoch % 10 == 0:\n",
    "            anomaly_img, _ = inject_anomaly(np.squeeze(slice_img))\n",
    "        else:\n",
    "            anomaly_img = slice_img\n",
    "\n",
    "        anomaly_img = np.expand_dims(np.squeeze(anomaly_img), axis=-1)  # Ensure channel dimension\n",
    "        augmented_img = augment_image(anomaly_img)\n",
    "        augmented_img = np.expand_dims(augmented_img, axis=0)  # Add batch dimension\n",
    "\n",
    "        original_img = np.expand_dims(original_img, axis=-1)\n",
    "        original_img = np.expand_dims(original_img, axis=0)\n",
    "\n",
    "        # Train the VAE on the augmented image and its reconstruction target\n",
    "        loss = vae.train_on_batch(augmented_img, original_img)\n",
    "\n",
    "    # Calculate epoch duration\n",
    "    epoch_time = time.time() - start_time\n",
    "\n",
    "    # Save model every 100 epochs\n",
    "    if epoch % 100 == 0:\n",
    "        vae.save(f'vae_model_epoch_{epoch}.h5')\n",
    "\n",
    "    # Display images and print loss every 50 epochs\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}/{epochs}, Loss: {loss:.4f}, Time: {epoch_time:.2f}s\")\n",
    "\n",
    "        # Reconstruct the image\n",
    "        reconstructed_img = vae.predict(augmented_img)\n",
    "\n",
    "        # Plot the images\n",
    "        fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "        \n",
    "        # Original image\n",
    "        axes[0].imshow(np.squeeze(original_img), cmap='gray')\n",
    "        axes[0].set_title(\"Original Image\")\n",
    "        \n",
    "        # Anomaly image\n",
    "        axes[1].imshow(np.squeeze(anomaly_img), cmap='gray')\n",
    "        axes[1].set_title(\"Anomaly Image\")\n",
    "        \n",
    "        # Augmented image\n",
    "        axes[2].imshow(np.squeeze(augmented_img), cmap='gray')\n",
    "        axes[2].set_title(\"Augmented Image\")\n",
    "        \n",
    "        # Reconstructed image\n",
    "        axes[3].imshow(np.squeeze(reconstructed_img), cmap='gray')\n",
    "        axes[3].set_title(\"Reconstructed Image\")\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3b4d17-f616-44a3-a871-0b922efd889d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, losses\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time  # Add time module\n",
    "from tensorflow.keras.preprocessing.image import smart_resize\n",
    "\n",
    "# Define the weighted VAE loss function\n",
    "def vae_loss(inputs, outputs, mu, log_var):\n",
    "    reconstruction_loss = tf.reduce_mean(losses.binary_crossentropy(inputs, outputs))\n",
    "    kl_loss = -0.5 * tf.reduce_mean(1 + log_var - tf.square(mu) - tf.exp(log_var))\n",
    "    return reconstruction_loss + 0.75 * kl_loss  # Weight reconstruction more heavily\n",
    "\n",
    "# Build the VAE model\n",
    "def build_vae(input_shape):\n",
    "    # Encoder\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    \n",
    "    mu = layers.Dense(128)(x)\n",
    "    log_var = layers.Dense(128)(x)\n",
    "\n",
    "    # Sampling function\n",
    "    def sampling(args):\n",
    "        mu, log_var = args\n",
    "        batch = tf.shape(mu)[0]\n",
    "        dim = tf.shape(mu)[1]\n",
    "        epsilon = tf.random.normal(shape=(batch, dim))\n",
    "        return mu + tf.exp(0.5 * log_var) * epsilon\n",
    "\n",
    "    z = layers.Lambda(sampling)([mu, log_var])\n",
    "\n",
    "    # Decoder\n",
    "    decoder_input = layers.Input(shape=(128,))\n",
    "    x = layers.Dense(64 * 64 * 128, activation='relu')(decoder_input)\n",
    "    x = layers.Reshape((64, 64, 128))(x)\n",
    "    x = layers.Conv2DTranspose(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)\n",
    "    x = layers.Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)\n",
    "    x = layers.Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)\n",
    "    outputs = layers.Conv2DTranspose(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    encoder = Model(inputs, [z, mu, log_var], name='encoder')\n",
    "    decoder = Model(decoder_input, outputs, name='decoder')\n",
    "\n",
    "    vae_outputs = decoder(encoder(inputs)[0])\n",
    "    vae = Model(inputs, vae_outputs, name='vae')\n",
    "\n",
    "    # Add loss function\n",
    "    vae.add_loss(vae_loss(inputs, vae_outputs, encoder(inputs)[1], encoder(inputs)[2]))\n",
    "    vae.compile(optimizer='adam')\n",
    "\n",
    "    return vae, encoder, decoder\n",
    "\n",
    "# Function to load preprocessed PNG slices from your dataset directory\n",
    "def load_slices_from_png(folder_path):\n",
    "    all_slices = []\n",
    "    for filename in sorted(os.listdir(folder_path)):\n",
    "        if filename.endswith('.png'):\n",
    "            img = cv2.imread(os.path.join(folder_path, filename), cv2.IMREAD_GRAYSCALE)\n",
    "            img = img / 255.0  # Normalize to [0,1]\n",
    "            img = np.expand_dims(img, axis=-1)  # Add channel dimension (512, 512, 1)\n",
    "            all_slices.append(img)\n",
    "    return np.array(all_slices)\n",
    "\n",
    "# Function to inject anomaly into an image\n",
    "def deform_and_inject_anomaly(image, window_size=200):\n",
    "    h, w = image.shape[:2]\n",
    "    \n",
    "    # Step 1: Apply global elastic deformation to the entire image\n",
    "    deformed_image = A.ElasticTransform(p=0.7, alpha=100, sigma=100)(image=image)[\"image\"]\n",
    "    \n",
    "    # Step 2: Select a random window area from the deformed image for anomaly injection\n",
    "    x, y = np.random.randint(0, h - window_size), np.random.randint(0, w - window_size)\n",
    "    anomaly_window = deformed_image[x:x+window_size, y:y+window_size]\n",
    "    \n",
    "    # Apply contrast change and elastic deformation specifically to the anomaly window\n",
    "    anomaly_window = A.RandomBrightnessContrast(p=1.0, brightness_limit=(-0.4, 0.4), contrast_limit=(-0.6, 0.6))(image=anomaly_window)[\"image\"]\n",
    "    anomaly_window = A.ElasticTransform(p=0.7, alpha=50, sigma=50)(image=anomaly_window)[\"image\"]\n",
    "    \n",
    "    # Create a random mask for a unique anomaly shape\n",
    "    mask = np.zeros_like(anomaly_window, dtype=np.uint8)\n",
    "    num_shapes = np.random.randint(1, 4)  # Number of shapes to create the mask\n",
    "\n",
    "    for _ in range(num_shapes):\n",
    "        shape_type = np.random.choice(['ellipse', 'polygon'])\n",
    "        if shape_type == 'ellipse':\n",
    "            center = (np.random.randint(0, window_size), np.random.randint(0, window_size))\n",
    "            axes = (np.random.randint(10, window_size // 2), np.random.randint(10, window_size // 2))\n",
    "            angle = np.random.randint(0, 180)\n",
    "            cv2.ellipse(mask, center, axes, angle, 0, 360, (255, 255, 255), -1)\n",
    "        elif shape_type == 'polygon':\n",
    "            num_points = np.random.randint(3, 7)\n",
    "            points = np.array([[\n",
    "                (np.random.randint(0, window_size), np.random.randint(0, window_size))\n",
    "                for _ in range(num_points)\n",
    "            ]], dtype=np.int32)\n",
    "            cv2.fillPoly(mask, points, (255, 255, 255))\n",
    "\n",
    "    # Apply mask to the anomaly window\n",
    "    masked_anomaly = cv2.bitwise_and(anomaly_window, anomaly_window, mask=mask)\n",
    "\n",
    "    # Place the modified, random-shaped window back into the deformed image\n",
    "    anomaly_image = deformed_image.copy()\n",
    "    new_x, new_y = np.random.randint(0, h - window_size), np.random.randint(0, w - window_size)\n",
    "\n",
    "    # Insert the masked anomaly at the new location\n",
    "    window_region = anomaly_image[new_x:new_x+window_size, new_y:new_y+window_size]\n",
    "    np.copyto(window_region, masked_anomaly, where=mask.astype(bool))\n",
    "\n",
    "    return anomaly_image, masked_anomaly\n",
    "\n",
    "# Albumentations augmentation\n",
    "def augment_image(image):\n",
    "    # Ensure that the image is a 2D or 3D array\n",
    "    if image.ndim == 3 and image.shape[-1] == 1:\n",
    "        image = image[..., 0]  # Remove the channel if it is a grayscale image with a single channel\n",
    "\n",
    "    image = (image * 255).astype(np.uint8)  # Convert to uint8\n",
    "    transform = A.Compose([\n",
    "        #  A.AdvancedBlur(p=0.5),\n",
    "        #  A.CLAHE(p=0.5),\n",
    "        #  A.Downscale(p=0.5),\n",
    "        #  A.Emboss(p=0.5),\n",
    "        #  A.Equalize(p=0.5),\n",
    "        # # A.FancyPCA(p=0.5),\n",
    "        #  A.GaussNoise(p=0.5),\n",
    "        #  A.RandomBrightnessContrast(p=0.5),\n",
    "        # # A.CoarseDropout(p=0.5),\n",
    "        # # A.PixelDropout(p=0.5)\n",
    "    ])\n",
    "    augmented = transform(image=image)\n",
    "    return augmented['image'] / 255.0\n",
    "\n",
    "# Load dataset from PNG images\n",
    "folder_path = r\"cropped\"  \n",
    "slices = load_slices_from_png(folder_path)\n",
    "\n",
    "# Resize to (512, 512) if needed\n",
    "slices = [smart_resize(slice_img, (512, 512)) for slice_img in slices]\n",
    "slices = np.array(slices)\n",
    "\n",
    "# Instantiate the VAE\n",
    "vae, encoder, decoder = build_vae(input_shape=(512, 512, 1))\n",
    "\n",
    "# Training loop\n",
    "epochs = 5000\n",
    "batch_size = 64\n",
    "\n",
    "vae.summary()\n",
    "\n",
    "for epoch in range(epochs + 1):\n",
    "    start_time = time.time()  # Start timer\n",
    "\n",
    "    for slice_img in slices:\n",
    "        original_img = slice_img.copy()  # Keep the original image\n",
    "        \n",
    "        # Deform the image and inject anomaly every 10 epochs\n",
    "        if epoch % 10 == 0:\n",
    "            anomaly_img, _ = deform_and_inject_anomaly(np.squeeze(slice_img))\n",
    "        else:\n",
    "            anomaly_img = slice_img\n",
    "\n",
    "        anomaly_img = np.expand_dims(np.squeeze(anomaly_img), axis=-1)  # Ensure channel dimension\n",
    "        augmented_img = augment_image(anomaly_img)\n",
    "        augmented_img = np.expand_dims(augmented_img, axis=0)  # Add batch dimension\n",
    "\n",
    "        original_img = np.expand_dims(original_img, axis=-1)\n",
    "        original_img = np.expand_dims(original_img, axis=0)\n",
    "\n",
    "        # Train the VAE on the augmented image and its reconstruction target\n",
    "        loss = vae.train_on_batch(augmented_img, original_img)\n",
    "\n",
    "    # Calculate epoch duration\n",
    "    epoch_time = time.time() - start_time\n",
    "\n",
    "    # Save model every 100 epochs\n",
    "    if epoch % 100 == 0:\n",
    "        vae.save(f'vae_model_epoch_{epoch}.h5')\n",
    "\n",
    "    # Display images and print loss every 50 epochs\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}/{epochs}, Loss: {loss:.4f}, Time: {epoch_time:.2f}s\")\n",
    "\n",
    "        # Reconstruct the image\n",
    "        reconstructed_img = vae.predict(augmented_img)\n",
    "\n",
    "        # Plot the images\n",
    "        fig, axes = plt.subplots(1, 4, figsize=(20, 5))\n",
    "        \n",
    "        # Original image\n",
    "        axes[0].imshow(np.squeeze(original_img), cmap='gray')\n",
    "        axes[0].set_title(\"Original Image\")\n",
    "        \n",
    "        # Anomaly image\n",
    "        axes[1].imshow(np.squeeze(anomaly_img), cmap='gray')\n",
    "        axes[1].set_title(\"Anomaly Image\")\n",
    "        \n",
    "        # Augmented image\n",
    "        axes[2].imshow(np.squeeze(augmented_img), cmap='gray')\n",
    "        axes[2].set_title(\"Augmented Image\")\n",
    "        \n",
    "        # Reconstructed image\n",
    "        axes[3].imshow(np.squeeze(reconstructed_img), cmap='gray')\n",
    "        axes[3].set_title(\"Reconstructed Image\")\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8dec06b-7382-4a1d-aab0-bd78ad43886e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
