{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d3dfaa-da8d-4d22-bc78-bd2cf44efb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses, Model\n",
    "from tensorflow.keras.models import Model\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8510c1f0-3cc2-47cb-b1dc-3e22ecb3540f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Function to compute SSIM and KL Divergence based loss\n",
    "def weighted_vae_loss(y_true, y_pred, mu, log_var, weight_ssim=0.8):\n",
    "    mse_loss = MeanSquaredError()(y_true, y_pred)\n",
    "    ssim_loss = 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, max_val=1.0))\n",
    "    kl_loss = -0.5 * tf.reduce_mean(1 + log_var - K.square(mu) - K.exp(log_var))\n",
    "    loss = weight_ssim * ssim_loss + (1 - weight_ssim) * mse_loss + kl_loss\n",
    "    return loss\n",
    "\n",
    "# VAE model definition\n",
    "def build_vae(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)  # 256x256\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)  # 128x128\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)  # 64x64\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    mu = layers.Dense(128)(x)\n",
    "    log_var = layers.Dense(128)(x)\n",
    "\n",
    "    def sampling(args):\n",
    "        mu, log_var = args\n",
    "        batch = tf.shape(mu)[0]\n",
    "        dim = tf.shape(mu)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return mu + tf.exp(0.5 * log_var) * epsilon\n",
    "\n",
    "    z = layers.Lambda(sampling)([mu, log_var])\n",
    "\n",
    "    # Decoder\n",
    "    decoder_input = layers.Input(shape=(128,))\n",
    "    x = layers.Dense(64 * 64 * 128, activation='relu')(decoder_input)\n",
    "    x = layers.Reshape((64, 64, 128))(x)\n",
    "    x = layers.Conv2DTranspose(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)  # 128x128\n",
    "    x = layers.Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)  # 256x256\n",
    "    x = layers.Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)  # 512x512\n",
    "\n",
    "    outputs = layers.Conv2DTranspose(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    encoder = Model(inputs, [z, mu, log_var], name='encoder')\n",
    "    decoder = Model(decoder_input, outputs, name='decoder')\n",
    "\n",
    "    vae_outputs = decoder(encoder(inputs)[0])\n",
    "    vae = Model(inputs, vae_outputs, name='vae')\n",
    "\n",
    "    vae.add_loss(weighted_vae_loss(inputs, vae_outputs, encoder(inputs)[1], encoder(inputs)[2]))\n",
    "    vae.compile(optimizer='adam')\n",
    "\n",
    "    return vae, encoder, decoder\n",
    "\n",
    "# Data augmentation using albumentations\n",
    "def augment_image(image):\n",
    "    transform = A.Compose([\n",
    "        A.CLAHE(p=1.0),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.ElasticTransform(p=0.5),\n",
    "    ])\n",
    "    augmented = transform(image=image)\n",
    "    return augmented['image']\n",
    "\n",
    "# Simulate training data (assuming a single 512x512 clean brain image)\n",
    "img_path = '61_processed_image_edit.png'\n",
    "image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE) # Assuming grayscale MRI image\n",
    "image = cv2.resize(image, (512, 512))  # Resize to (512, 512)\n",
    "\n",
    "# Albumentations requires the input to have 3 channels, so expand dimensions\n",
    "image = np.expand_dims(image, axis=-1)\n",
    "image = image / 255.0  # Normalize\n",
    "\n",
    "# Build VAE model\n",
    "vae, encoder, decoder = build_vae(input_shape=(512, 512, 1))\n",
    "\n",
    "# Train the VAE\n",
    "epochs = 5000\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(epochs+1):\n",
    "    # Perform data augmentation on each epoch\n",
    "    augmented_image = augment_image(image)\n",
    "    augmented_image = np.expand_dims(augmented_image, axis=0)  # Add batch dimension\n",
    "\n",
    "    # Train the model\n",
    "    vae.fit(augmented_image, augmented_image, epochs=1, batch_size=batch_size, verbose=1)\n",
    "\n",
    "    # Print and display outputs every 50 epochs\n",
    "    if epoch % 50 == 0:\n",
    "        reconstructed = vae.predict(np.expand_dims(image, axis=0))\n",
    "        reconstructed = np.squeeze(reconstructed)  # Remove the batch dimension\n",
    "\n",
    "        print(f\"Epoch: {epoch}\")\n",
    "        \n",
    "        # Display original, augmented, and reconstructed images\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "        ax[0].imshow(np.squeeze(image), cmap='gray')\n",
    "        ax[0].set_title(\"Original Image\")\n",
    "        ax[0].axis(\"off\")\n",
    "\n",
    "        ax[1].imshow(np.squeeze(augmented_image), cmap='gray')\n",
    "        ax[1].set_title(\"Augmented Image\")\n",
    "        ax[1].axis(\"off\")\n",
    "\n",
    "        ax[2].imshow(reconstructed, cmap='gray')\n",
    "        ax[2].set_title(\"Reconstructed Image\")\n",
    "        ax[2].axis(\"off\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    # Save model every 100 epochs\n",
    "    if epoch % 100 == 0:\n",
    "        vae.save(f\"vae_model_epoch_{epoch}.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a3a245-f123-43de-b96a-04747e9cf494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# Define the same VAE architecture used for saving the model\n",
    "def build_vae(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)  # 256x256\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)  # 128x128\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)  # 64x64\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    mu = layers.Dense(128)(x)\n",
    "    log_var = layers.Dense(128)(x)\n",
    "\n",
    "    def sampling(args):\n",
    "        mu, log_var = args\n",
    "        batch = tf.shape(mu)[0]\n",
    "        dim = tf.shape(mu)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return mu + tf.exp(0.5 * log_var) * epsilon\n",
    "\n",
    "    z = layers.Lambda(sampling)([mu, log_var])\n",
    "\n",
    "    # Decoder\n",
    "    decoder_input = layers.Input(shape=(128,))\n",
    "    x = layers.Dense(64 * 64 * 128, activation='relu')(decoder_input)\n",
    "    x = layers.Reshape((64, 64, 128))(x)\n",
    "    x = layers.Conv2DTranspose(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)  # 128x128\n",
    "    x = layers.Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)  # 256x256\n",
    "    x = layers.Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)  # 512x512\n",
    "\n",
    "    outputs = layers.Conv2DTranspose(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    encoder = Model(inputs, [z, mu, log_var], name='encoder')\n",
    "    decoder = Model(decoder_input, outputs, name='decoder')\n",
    "\n",
    "    vae_outputs = decoder(encoder(inputs)[0])\n",
    "    vae = Model(inputs, vae_outputs, name='vae')\n",
    "\n",
    "    return vae, encoder, decoder\n",
    "\n",
    "# Load the model\n",
    "vae, encoder, decoder = build_vae(input_shape=(512, 512, 1))\n",
    "vae.load_weights(\"vae_model_epoch_10000.h5\")  # Replace with the correct model path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed3fea4-d9c7-4445-b84f-bc67f8809276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the anomalous image in the same way as the clean image\n",
    "\n",
    "anomalous_img_path = 'test/processed_image_edit.png'\n",
    "anomalous_image = cv2.imread(anomalous_img_path, cv2.IMREAD_GRAYSCALE)\n",
    "anomalous_image = cv2.resize(anomalous_image, (512, 512))\n",
    "anomalous_image = anomalous_image / 255.0\n",
    "anomalous_image = np.expand_dims(np.expand_dims(anomalous_image, axis=0), axis=-1)\n",
    "\n",
    "\n",
    "# Predict and compute anomaly\n",
    "reconstructed_anomalous = vae.predict(anomalous_image)\n",
    "difference = np.abs(anomalous_image - reconstructed_anomalous)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Anomalous Image\")\n",
    "plt.imshow(np.squeeze(anomalous_image), cmap='gray')\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Reconstructed Clean Image\")\n",
    "plt.imshow(np.squeeze(reconstructed_anomalous), cmap='gray')\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Tumor Region (Difference)\")\n",
    "plt.imshow(np.squeeze(difference), cmap='hot')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a80f35c-b23c-44b9-aa07-20716c8197b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load and preprocess the anomalous image in the same way as the clean image\n",
    "anomalous_img_path = 'test/processed_image_edit.png'\n",
    "anomalous_image = cv2.imread(anomalous_img_path, cv2.IMREAD_GRAYSCALE)\n",
    "anomalous_image = cv2.resize(anomalous_image, (512, 512))\n",
    "anomalous_image = anomalous_image / 255.0\n",
    "anomalous_image = np.expand_dims(np.expand_dims(anomalous_image, axis=0), axis=-1)\n",
    "\n",
    "# Predict and compute anomaly\n",
    "reconstructed_anomalous = vae.predict(anomalous_image)\n",
    "difference = np.abs(anomalous_image - reconstructed_anomalous)\n",
    "\n",
    "# Thresholding to create a binary mask\n",
    "threshold_value = 0.1  # Set a threshold value to identify anomaly\n",
    "binary_mask = difference > threshold_value  # Binary mask (True where difference > threshold)\n",
    "\n",
    "# Convert the mask to float for visualization purposes\n",
    "binary_mask = binary_mask.astype(np.float32)\n",
    "\n",
    "# Plot the anomalous image, reconstructed clean image, and the tumor region (binary mask)\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Anomalous Image\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Anomalous Image\")\n",
    "plt.imshow(np.squeeze(anomalous_image), cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "# Reconstructed Clean Image\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Reconstructed Clean Image\")\n",
    "plt.imshow(np.squeeze(reconstructed_anomalous), cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "# Tumor Region (Binary Mask)\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Tumor Region (Binary Mask)\")\n",
    "plt.imshow(np.squeeze(binary_mask), cmap='hot')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acd8990-48d6-46e0-8082-4221ca6b8347",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load and preprocess the anomalous image in the same way as the clean image\n",
    "anomalous_img_path = 'test/processed_image_edit.png'\n",
    "anomalous_image = cv2.imread(anomalous_img_path, cv2.IMREAD_GRAYSCALE)\n",
    "anomalous_image = cv2.resize(anomalous_image, (512, 512))\n",
    "anomalous_image = anomalous_image / 255.0\n",
    "anomalous_image = np.expand_dims(np.expand_dims(anomalous_image, axis=0), axis=-1)\n",
    "\n",
    "# Pass the image through the encoder to get the latent space (z, mu, log_var)\n",
    "z, mu, log_var = encoder.predict(anomalous_image)\n",
    "\n",
    "# Decode the latent representation (z) to reconstruct the clean image\n",
    "reconstructed_anomalous = decoder.predict(z)\n",
    "\n",
    "# Compute the difference between the original anomalous image and the reconstructed image\n",
    "difference = np.abs(anomalous_image - reconstructed_anomalous)\n",
    "\n",
    "# Thresholding to create a binary mask for the tumor region\n",
    "threshold_value = 0.2  # You can adjust this value\n",
    "binary_mask = difference > threshold_value\n",
    "binary_mask = binary_mask.astype(np.float32)\n",
    "\n",
    "# Visualize the original anomalous image, reconstructed clean image, and the tumor region (binary mask)\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Anomalous Image\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.title(\"Anomalous Image\")\n",
    "plt.imshow(np.squeeze(anomalous_image), cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "# Latent Space (mu)\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.title(\"Latent Space (mu)\")\n",
    "plt.plot(mu[0])  # Plot the latent space (mu) for visualization\n",
    "plt.axis('on')\n",
    "\n",
    "# Latent Space (log_var)\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.title(\"Latent Space (log_var)\")\n",
    "plt.plot(log_var[0])  # Plot the latent space (log_var) for visualization\n",
    "plt.axis('on')\n",
    "\n",
    "# Reconstructed Clean Image\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.title(\"Reconstructed Clean Image\")\n",
    "plt.imshow(np.squeeze(reconstructed_anomalous), cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "# Tumor Region (Difference)\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.title(\"Tumor Region (Difference)\")\n",
    "plt.imshow(np.squeeze(difference), cmap='hot')\n",
    "plt.axis('off')\n",
    "\n",
    "# Tumor Region (Binary Mask)\n",
    "plt.subplot(2, 3, 6)\n",
    "plt.title(\"Tumor Region (Binary Mask)\")\n",
    "plt.imshow(np.squeeze(binary_mask), cmap='hot')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Optionally, return the latent space vectors for further analysis\n",
    "print(\"Latent space (mu):\", mu[0])\n",
    "print(\"Latent space (log_var):\", log_var[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e429949a-a04b-4585-92cf-7e36ad57f7c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Function to calculate reconstruction error\n",
    "def calculate_reconstruction_error(original, reconstructed):\n",
    "    return np.mean(np.square(original - reconstructed), axis=(1, 2, 3))  # MSE error per image\n",
    "\n",
    "# Function to classify as anomalous based on a threshold\n",
    "def classify_anomalies(reconstruction_error, threshold):\n",
    "    return reconstruction_error > threshold\n",
    "\n",
    "# Load test images (assuming grayscale 512x512 MRI images)\n",
    "def load_image(img_path):\n",
    "    image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    image = cv2.resize(image, (512, 512))\n",
    "    image = np.expand_dims(image, axis=-1)  # Add channel dimension\n",
    "    image = image / 255.0  # Normalize\n",
    "    return np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "\n",
    "# Define a function to evaluate model performance and show reconstructed images\n",
    "def evaluate_model_and_display(vae, test_images, true_labels, threshold):\n",
    "    reconstruction_errors = []\n",
    "    predictions = []\n",
    "    \n",
    "    for img in test_images:\n",
    "        original = img\n",
    "        reconstructed = vae.predict(img)  # Predict reconstructed image\n",
    "        error = calculate_reconstruction_error(original, reconstructed)\n",
    "        reconstruction_errors.append(error)\n",
    "        predictions.append(classify_anomalies(error, threshold))\n",
    "    \n",
    "        # Display original and reconstructed images\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        \n",
    "        # Original image\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(np.squeeze(original), cmap='gray')\n",
    "        plt.title(\"Original Image\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        # Reconstructed image\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(np.squeeze(reconstructed), cmap='gray')\n",
    "        if classify_anomalies(error, threshold):\n",
    "            plt.title(\"Reconstructed Image (Anomalous)\")\n",
    "        else:\n",
    "            plt.title(\"Reconstructed Image (Normal)\")\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    reconstruction_errors = np.array(reconstruction_errors)\n",
    "    predictions = np.array(predictions)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    precision = precision_score(true_labels, predictions)\n",
    "    recall = recall_score(true_labels, predictions)\n",
    "    f1 = f1_score(true_labels, predictions)\n",
    "    roc_auc = roc_auc_score(true_labels, reconstruction_errors)\n",
    "\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1-Score: {f1}\")\n",
    "    print(f\"ROC-AUC: {roc_auc}\")\n",
    "\n",
    "    return predictions, reconstruction_errors\n",
    "\n",
    "# Example usage\n",
    "test_image_paths = ['test/processed_image_edit.png',r\"C:\\Users\\priya\\Documents\\DL project\\test 2\\processed_image_edit.png\",r\"C:\\Users\\priya\\Documents\\DL project\\test 3\\processed_image_edit.png\"]  # Replace with actual image paths\n",
    "test_images = [load_image(path) for path in test_image_paths]\n",
    "true_labels = [1, 0, 0]  # Ground truth labels (0 = normal, 1 = anomalous)\n",
    "\n",
    "# Load the saved VAE model\n",
    "vae, encoder, decoder = build_vae(input_shape=(512, 512, 1))\n",
    "vae.load_weights(\"vae_model_epoch_9900.h5\")  # Replace with the correct path\n",
    "\n",
    "# Set an anomaly threshold\n",
    "anomaly_threshold = 0.05  # You can tune this based on your validation results\n",
    "\n",
    "# Evaluate the model and display reconstructed images\n",
    "predictions, reconstruction_errors = evaluate_model_and_display(vae, test_images, true_labels, anomaly_threshold)\n",
    "\n",
    "# Plot the reconstruction errors\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(reconstruction_errors, label=\"Reconstruction Errors\")\n",
    "plt.axhline(y=anomaly_threshold, color='r', linestyle='--', label=\"Anomaly Threshold\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc83799-48bf-493d-8b10-358586f4b316",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "# Function to load an image\n",
    "def load_image(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Load as grayscale\n",
    "    image = cv2.resize(image, (512, 512))  # Resize to the required dimensions\n",
    "    return image / 255.0  # Normalize to [0, 1]\n",
    "\n",
    "# Function to compute SSIM map and score\n",
    "def compute_ssim_map(original, reconstructed):\n",
    "    ssim_map = ssim(original, reconstructed, full=True, data_range=1.0)[1]\n",
    "    ssim_score = np.mean(ssim_map)  # Average SSIM score\n",
    "    return ssim_map, ssim_score\n",
    "\n",
    "# Function to highlight anomalous regions based on SSIM\n",
    "def highlight_anomalous_regions(ssim_map, threshold):\n",
    "    # Create the anomaly mask\n",
    "    anomaly_mask = ssim_map < threshold\n",
    "    return anomaly_mask.astype(float)  # Ensure the mask is in float format for visualization\n",
    "\n",
    "# Function to visualize original, reconstructed, and anomaly mask\n",
    "def visualize_anomalous_regions(original, reconstructed, anomaly_mask):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Original image\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(original, cmap='gray')\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Anomaly mask\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(anomaly_mask, cmap='hot', alpha=0.6)  # Display anomalous regions using heatmap\n",
    "    plt.title(\"Anomalous Regions (SSIM < Threshold)\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Reconstructed image\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(reconstructed, cmap='gray')\n",
    "    plt.title(\"Reconstructed Image\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Function to evaluate model and display anomalies\n",
    "def evaluate_and_display_anomalies(vae, test_images, threshold_ssim):\n",
    "    for original in test_images:\n",
    "        original = np.expand_dims(original, axis=-1)  # Add channel dimension\n",
    "        original = np.expand_dims(original, axis=0)   # Add batch dimension\n",
    "\n",
    "        # Reconstruct the image\n",
    "        reconstructed = vae.predict(original)\n",
    "\n",
    "        # Compute SSIM map and score\n",
    "        ssim_map, ssim_score = compute_ssim_map(np.squeeze(original), np.squeeze(reconstructed))\n",
    "\n",
    "        # Highlight anomalous regions\n",
    "        anomaly_mask = highlight_anomalous_regions(ssim_map, threshold=threshold_ssim)\n",
    "\n",
    "        # Visualize the anomalies\n",
    "        visualize_anomalous_regions(np.squeeze(original), np.squeeze(reconstructed), anomaly_mask)\n",
    "\n",
    "# Example usage\n",
    "test_image_paths = [\n",
    "    'test/processed_image_edit.png', \n",
    "    r\"C:\\Users\\priya\\Documents\\DL project\\test 2\\processed_image_edit.png\",\n",
    "    r\"C:\\Users\\priya\\Documents\\DL project\\test 3\\processed_image_edit.png\"\n",
    "]  # Replace with actual image paths\n",
    "\n",
    "# Load test images\n",
    "test_images = [load_image(path) for path in test_image_paths]\n",
    "\n",
    "# Load the saved VAE model\n",
    "vae, encoder, decoder = build_vae(input_shape=(512, 512, 1))\n",
    "vae.load_weights(\"vae_model_epoch_15000.h5\")  # Replace with the correct path\n",
    "\n",
    "# Set SSIM threshold for anomaly detection\n",
    "ssim_threshold = 0.85  # Adjust this threshold based on your use case\n",
    "\n",
    "# Evaluate the model and display anomalies\n",
    "evaluate_and_display_anomalies(vae, test_images, threshold_ssim=ssim_threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fc5e6e-2b7b-48a1-bc64-3edc8ab0843d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ad27b7-a1a3-4dbf-a495-dc32f3a7669e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef524ed2-14bb-4afb-889e-5b8f20b4a119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b754c3-0b5a-491e-9b07-47929fea6c1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67481e03-6f5e-4da6-94fe-7effc21342ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses, Model\n",
    "from tensorflow.keras.models import Model\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "\n",
    "# Function to compute SSIM and KL Divergence based loss\n",
    "def weighted_vae_loss(y_true, y_pred, mu, log_var, weight_ssim=0.8):\n",
    "    mse_loss = MeanSquaredError()(y_true, y_pred)\n",
    "    ssim_loss = 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, max_val=1.0))\n",
    "    kl_loss = -0.5 * tf.reduce_mean(1 + log_var - K.square(mu) - K.exp(log_var))\n",
    "    loss = weight_ssim * ssim_loss + (1 - weight_ssim) * mse_loss + kl_loss\n",
    "    return loss\n",
    "\n",
    "# VAE model definition\n",
    "def build_vae(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)  # 256x256\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)  # 128x128\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)  # 64x64\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    mu = layers.Dense(128)(x)\n",
    "    log_var = layers.Dense(128)(x)\n",
    "\n",
    "    def sampling(args):\n",
    "        mu, log_var = args\n",
    "        batch = tf.shape(mu)[0]\n",
    "        dim = tf.shape(mu)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return mu + tf.exp(0.5 * log_var) * epsilon\n",
    "\n",
    "    z = layers.Lambda(sampling)([mu, log_var])\n",
    "\n",
    "    # Decoder\n",
    "    decoder_input = layers.Input(shape=(128,))\n",
    "    x = layers.Dense(64 * 64 * 128, activation='relu')(decoder_input)\n",
    "    x = layers.Reshape((64, 64, 128))(x)\n",
    "    x = layers.Conv2DTranspose(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)  # 128x128\n",
    "    x = layers.Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)  # 256x256\n",
    "    x = layers.Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)  # 512x512\n",
    "\n",
    "    outputs = layers.Conv2DTranspose(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    encoder = Model(inputs, [z, mu, log_var], name='encoder')\n",
    "    decoder = Model(decoder_input, outputs, name='decoder')\n",
    "\n",
    "    vae_outputs = decoder(encoder(inputs)[0])\n",
    "    vae = Model(inputs, vae_outputs, name='vae')\n",
    "\n",
    "    vae.add_loss(weighted_vae_loss(inputs, vae_outputs, encoder(inputs)[1], encoder(inputs)[2]))\n",
    "    vae.compile(optimizer='adam')\n",
    "\n",
    "    return vae, encoder, decoder\n",
    "\n",
    "# Data augmentation using albumentations\n",
    "def augment_image(image):\n",
    "    # Convert to float32 for compatibility with augmentation operations\n",
    "    image = image.astype(np.float32)\n",
    "\n",
    "    transform = A.Compose([\n",
    "        A.AdvancedBlur(p=0.5),\n",
    "        A.CLAHE(p=0.5),\n",
    "        A.Downscale(p=0.5),\n",
    "        A.Emboss(p=0.5),\n",
    "        A.Equalize(p=0.5),\n",
    "        A.FancyPCA(p=0.5),\n",
    "        A.GaussNoise(p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.5),\n",
    "        A.CoarseDropout(p=0.5),\n",
    "        A.PixelDropout(p=0.5)\n",
    "    ])\n",
    "    \n",
    "    augmented = transform(image=image)\n",
    "    return augmented['image']\n",
    "\n",
    "\n",
    "# Simulate training data (assuming a single 512x512 clean brain image)\n",
    "img_path = '61_processed_image_edit.png'\n",
    "image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Assuming grayscale MRI image\n",
    "image = cv2.resize(image, (512, 512))  # Resize to (512, 512)\n",
    "\n",
    "# Albumentations requires the input to have 3 channels, so expand dimensions\n",
    "image = np.expand_dims(image, axis=-1)\n",
    "image = image / 255.0  # Normalize\n",
    "\n",
    "# Build VAE model\n",
    "vae, encoder, decoder = build_vae(input_shape=(512, 512, 1))\n",
    "\n",
    "# Train the VAE\n",
    "epochs = 5000\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(epochs + 1):\n",
    "    # Perform data augmentation on each epoch\n",
    "    augmented_image = augment_image(image)\n",
    "    augmented_image = np.expand_dims(augmented_image, axis=0)  # Add batch dimension\n",
    "\n",
    "    # Train the model\n",
    "    vae.fit(augmented_image, augmented_image, epochs=1, batch_size=batch_size, verbose=1)\n",
    "\n",
    "    # Print and display outputs every 50 epochs\n",
    "    if epoch % 50 == 0:\n",
    "        reconstructed = vae.predict(np.expand_dims(image, axis=0))\n",
    "        reconstructed = np.squeeze(reconstructed)  # Remove the batch dimension\n",
    "\n",
    "        print(f\"Epoch: {epoch}\")\n",
    "        \n",
    "        # Display original, augmented, and reconstructed images\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "        ax[0].imshow(np.squeeze(image), cmap='gray')\n",
    "        ax[0].set_title(\"Original Image\")\n",
    "        ax[0].axis(\"off\")\n",
    "\n",
    "        ax[1].imshow(np.squeeze(augmented_image), cmap='gray')\n",
    "        ax[1].set_title(\"Augmented Image\")\n",
    "        ax[1].axis(\"off\")\n",
    "\n",
    "        ax[2].imshow(reconstructed, cmap='gray')\n",
    "        ax[2].set_title(\"Reconstructed Image\")\n",
    "        ax[2].axis(\"off\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    # Save model every 100 epochs\n",
    "    if epoch % 100 == 0:\n",
    "        vae.save(f\"vae_model_epoch_{epoch}.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bc1d40-d810-4418-9c3b-f2ede7807fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# Define the same VAE architecture used for saving the model\n",
    "def build_vae(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)  # 256x256\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)  # 128x128\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)  # 64x64\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    mu = layers.Dense(128)(x)\n",
    "    log_var = layers.Dense(128)(x)\n",
    "\n",
    "    def sampling(args):\n",
    "        mu, log_var = args\n",
    "        batch = tf.shape(mu)[0]\n",
    "        dim = tf.shape(mu)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return mu + tf.exp(0.5 * log_var) * epsilon\n",
    "\n",
    "    z = layers.Lambda(sampling)([mu, log_var])\n",
    "\n",
    "    # Decoder\n",
    "    decoder_input = layers.Input(shape=(128,))\n",
    "    x = layers.Dense(64 * 64 * 128, activation='relu')(decoder_input)\n",
    "    x = layers.Reshape((64, 64, 128))(x)\n",
    "    x = layers.Conv2DTranspose(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)  # 128x128\n",
    "    x = layers.Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)  # 256x256\n",
    "    x = layers.Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)  # 512x512\n",
    "\n",
    "    outputs = layers.Conv2DTranspose(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    encoder = Model(inputs, [z, mu, log_var], name='encoder')\n",
    "    decoder = Model(decoder_input, outputs, name='decoder')\n",
    "\n",
    "    vae_outputs = decoder(encoder(inputs)[0])\n",
    "    vae = Model(inputs, vae_outputs, name='vae')\n",
    "\n",
    "    return vae, encoder, decoder\n",
    "\n",
    "# Load the model\n",
    "vae, encoder, decoder = build_vae(input_shape=(512, 512, 1))\n",
    "vae.load_weights(\"vae_model_epoch_5000.h5\")  # Replace with the correct model path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8746051c-7a63-48b3-b053-0febf20dcee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the anomalous image in the same way as the clean image\n",
    "\n",
    "anomalous_img_path = 'test/processed_image_edit.png'\n",
    "anomalous_image = cv2.imread(anomalous_img_path, cv2.IMREAD_GRAYSCALE)\n",
    "anomalous_image = cv2.resize(anomalous_image, (512, 512))\n",
    "anomalous_image = anomalous_image / 255.0\n",
    "anomalous_image = np.expand_dims(np.expand_dims(anomalous_image, axis=0), axis=-1)\n",
    "\n",
    "\n",
    "# Predict and compute anomaly\n",
    "reconstructed_anomalous = vae.predict(anomalous_image)\n",
    "difference = np.abs(anomalous_image - reconstructed_anomalous)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Anomalous Image\")\n",
    "plt.imshow(np.squeeze(anomalous_image), cmap='gray')\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Reconstructed Clean Image\")\n",
    "plt.imshow(np.squeeze(reconstructed_anomalous), cmap='gray')\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Tumor Region (Difference)\")\n",
    "plt.imshow(np.squeeze(difference), cmap='hot')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6c557c-ddb3-4dc4-96e6-01621835f2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load and preprocess the anomalous image in the same way as the clean image\n",
    "anomalous_img_path = 'test/processed_image_edit.png'\n",
    "anomalous_image = cv2.imread(anomalous_img_path, cv2.IMREAD_GRAYSCALE)\n",
    "anomalous_image = cv2.resize(anomalous_image, (512, 512))\n",
    "anomalous_image = anomalous_image / 255.0\n",
    "anomalous_image = np.expand_dims(np.expand_dims(anomalous_image, axis=0), axis=-1)\n",
    "\n",
    "# Predict and compute anomaly\n",
    "reconstructed_anomalous = vae.predict(anomalous_image)\n",
    "difference = np.abs(anomalous_image - reconstructed_anomalous)\n",
    "\n",
    "# Thresholding to create a binary mask\n",
    "threshold_value = 0.1  # Set a threshold value to identify anomaly\n",
    "binary_mask = difference > threshold_value  # Binary mask (True where difference > threshold)\n",
    "\n",
    "# Convert the mask to float for visualization purposes\n",
    "binary_mask = binary_mask.astype(np.float32)\n",
    "\n",
    "# Plot the anomalous image, reconstructed clean image, and the tumor region (binary mask)\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Anomalous Image\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Anomalous Image\")\n",
    "plt.imshow(np.squeeze(anomalous_image), cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "# Reconstructed Clean Image\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Reconstructed Clean Image\")\n",
    "plt.imshow(np.squeeze(reconstructed_anomalous), cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "# Tumor Region (Binary Mask)\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Tumor Region (Binary Mask)\")\n",
    "plt.imshow(np.squeeze(binary_mask), cmap='hot')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57131d2-e9b0-4dab-8810-8316d1417e9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load and preprocess the anomalous image in the same way as the clean image\n",
    "anomalous_img_path = 'test/processed_image_edit.png'\n",
    "anomalous_image = cv2.imread(anomalous_img_path, cv2.IMREAD_GRAYSCALE)\n",
    "anomalous_image = cv2.resize(anomalous_image, (512, 512))\n",
    "anomalous_image = anomalous_image / 255.0\n",
    "anomalous_image = np.expand_dims(np.expand_dims(anomalous_image, axis=0), axis=-1)\n",
    "\n",
    "# Pass the image through the encoder to get the latent space (z, mu, log_var)\n",
    "z, mu, log_var = encoder.predict(anomalous_image)\n",
    "\n",
    "# Decode the latent representation (z) to reconstruct the clean image\n",
    "reconstructed_anomalous = decoder.predict(z)\n",
    "\n",
    "# Compute the difference between the original anomalous image and the reconstructed image\n",
    "difference = np.abs(anomalous_image - reconstructed_anomalous)\n",
    "\n",
    "# Thresholding to create a binary mask for the tumor region\n",
    "threshold_value = 0.2  # You can adjust this value\n",
    "binary_mask = difference > threshold_value\n",
    "binary_mask = binary_mask.astype(np.float32)\n",
    "\n",
    "# Visualize the original anomalous image, reconstructed clean image, and the tumor region (binary mask)\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Anomalous Image\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.title(\"Anomalous Image\")\n",
    "plt.imshow(np.squeeze(anomalous_image), cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "# Latent Space (mu)\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.title(\"Latent Space (mu)\")\n",
    "plt.plot(mu[0])  # Plot the latent space (mu) for visualization\n",
    "plt.axis('on')\n",
    "\n",
    "# Latent Space (log_var)\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.title(\"Latent Space (log_var)\")\n",
    "plt.plot(log_var[0])  # Plot the latent space (log_var) for visualization\n",
    "plt.axis('on')\n",
    "\n",
    "# Reconstructed Clean Image\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.title(\"Reconstructed Clean Image\")\n",
    "plt.imshow(np.squeeze(reconstructed_anomalous), cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "# Tumor Region (Difference)\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.title(\"Tumor Region (Difference)\")\n",
    "plt.imshow(np.squeeze(difference), cmap='hot')\n",
    "plt.axis('off')\n",
    "\n",
    "# Tumor Region (Binary Mask)\n",
    "plt.subplot(2, 3, 6)\n",
    "plt.title(\"Tumor Region (Binary Mask)\")\n",
    "plt.imshow(np.squeeze(binary_mask), cmap='hot')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02d2706-c46a-4778-9eb4-0736b597609c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Function to calculate reconstruction error\n",
    "def calculate_reconstruction_error(original, reconstructed):\n",
    "    return np.mean(np.square(original - reconstructed), axis=(1, 2, 3))  # MSE error per image\n",
    "\n",
    "# Function to classify as anomalous based on a threshold\n",
    "def classify_anomalies(reconstruction_error, threshold):\n",
    "    return reconstruction_error > threshold\n",
    "\n",
    "# Load test images (assuming grayscale 512x512 MRI images)\n",
    "def load_image(img_path):\n",
    "    image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    image = cv2.resize(image, (512, 512))\n",
    "    image = np.expand_dims(image, axis=-1)  # Add channel dimension\n",
    "    image = image / 255.0  # Normalize\n",
    "    return np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "\n",
    "# Define a function to evaluate model performance and show reconstructed images\n",
    "def evaluate_model_and_display(vae, test_images, true_labels, threshold):\n",
    "    reconstruction_errors = []\n",
    "    predictions = []\n",
    "    \n",
    "    for img in test_images:\n",
    "        original = img\n",
    "        reconstructed = vae.predict(img)  # Predict reconstructed image\n",
    "        error = calculate_reconstruction_error(original, reconstructed)\n",
    "        reconstruction_errors.append(error)\n",
    "        predictions.append(classify_anomalies(error, threshold))\n",
    "    \n",
    "        # Display original and reconstructed images\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        \n",
    "        # Original image\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(np.squeeze(original), cmap='gray')\n",
    "        plt.title(\"Original Image\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        # Reconstructed image\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(np.squeeze(reconstructed), cmap='gray')\n",
    "        if classify_anomalies(error, threshold):\n",
    "            plt.title(\"Reconstructed Image (Anomalous)\")\n",
    "        else:\n",
    "            plt.title(\"Reconstructed Image (Normal)\")\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    reconstruction_errors = np.array(reconstruction_errors)\n",
    "    predictions = np.array(predictions)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    precision = precision_score(true_labels, predictions)\n",
    "    recall = recall_score(true_labels, predictions)\n",
    "    f1 = f1_score(true_labels, predictions)\n",
    "    roc_auc = roc_auc_score(true_labels, reconstruction_errors)\n",
    "\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1-Score: {f1}\")\n",
    "    print(f\"ROC-AUC: {roc_auc}\")\n",
    "\n",
    "    return predictions, reconstruction_errors\n",
    "\n",
    "# Example usage\n",
    "test_image_paths = ['test/processed_image_edit.png',r\"C:\\Users\\priya\\Documents\\DL project\\test 2\\processed_image_edit.png\",r\"C:\\Users\\priya\\Documents\\DL project\\test 3\\processed_image_edit.png\"]  # Replace with actual image paths\n",
    "test_images = [load_image(path) for path in test_image_paths]\n",
    "true_labels = [1, 0, 0]  # Ground truth labels (0 = normal, 1 = anomalous)\n",
    "\n",
    "# Load the saved VAE model\n",
    "vae, encoder, decoder = build_vae(input_shape=(512, 512, 1))\n",
    "vae.load_weights(\"vae_model_epoch_5000.h5\")  # Replace with the correct path\n",
    "\n",
    "# Set an anomaly threshold\n",
    "anomaly_threshold = 0.05  # You can tune this based on your validation results\n",
    "\n",
    "# Evaluate the model and display reconstructed images\n",
    "predictions, reconstruction_errors = evaluate_model_and_display(vae, test_images, true_labels, anomaly_threshold)\n",
    "\n",
    "# Plot the reconstruction errors\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(reconstruction_errors, label=\"Reconstruction Errors\")\n",
    "plt.axhline(y=anomaly_threshold, color='r', linestyle='--', label=\"Anomaly Threshold\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5c42b7-82eb-458d-bcb0-c886c71664ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600c2e80-21e0-41b1-985c-066bc0de008a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8f89c3-2ba4-4385-b751-6067957cec32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e28fec4-984f-4777-a76a-7ab5bdb68341",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461bbab8-78c9-4f6f-869a-bcfd2996a52a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438cd6a7-a0b2-4ab5-a580-0124625e8c05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feabd54a-fa1c-4793-b991-1b8d107048ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601f8452-085f-4fad-b737-b50d4f4d06a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses, Model\n",
    "from tensorflow.keras.models import Model\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "\n",
    "# Function to compute SSIM and KL Divergence based loss\n",
    "def weighted_vae_loss(y_true, y_pred, mu, log_var, weight_ssim=0.8):\n",
    "    mse_loss = MeanSquaredError()(y_true, y_pred)\n",
    "    ssim_loss = 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, max_val=1.0))\n",
    "    kl_loss = -0.5 * tf.reduce_mean(1 + log_var - K.square(mu) - K.exp(log_var))\n",
    "    loss = weight_ssim * ssim_loss + (1 - weight_ssim) * mse_loss + kl_loss\n",
    "    return loss\n",
    "\n",
    "# VAE model definition\n",
    "def build_vae(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)  # 256x256\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)  # 128x128\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)  # 64x64\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    mu = layers.Dense(128)(x)\n",
    "    log_var = layers.Dense(128)(x)\n",
    "\n",
    "    def sampling(args):\n",
    "        mu, log_var = args\n",
    "        batch = tf.shape(mu)[0]\n",
    "        dim = tf.shape(mu)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return mu + tf.exp(0.5 * log_var) * epsilon\n",
    "\n",
    "    z = layers.Lambda(sampling)([mu, log_var])\n",
    "\n",
    "    # Decoder\n",
    "    decoder_input = layers.Input(shape=(128,))\n",
    "    x = layers.Dense(64 * 64 * 128, activation='relu')(decoder_input)\n",
    "    x = layers.Reshape((64, 64, 128))(x)\n",
    "    x = layers.Conv2DTranspose(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)  # 128x128\n",
    "    x = layers.Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)  # 256x256\n",
    "    x = layers.Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)  # 512x512\n",
    "\n",
    "    outputs = layers.Conv2DTranspose(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    encoder = Model(inputs, [z, mu, log_var], name='encoder')\n",
    "    decoder = Model(decoder_input, outputs, name='decoder')\n",
    "\n",
    "    vae_outputs = decoder(encoder(inputs)[0])\n",
    "    vae = Model(inputs, vae_outputs, name='vae')\n",
    "\n",
    "    vae.add_loss(weighted_vae_loss(inputs, vae_outputs, encoder(inputs)[1], encoder(inputs)[2]))\n",
    "    vae.compile(optimizer='adam')\n",
    "\n",
    "    return vae, encoder, decoder\n",
    "\n",
    "# Data augmentation using albumentations\n",
    "def augment_image(image):\n",
    "    # Convert to float32 for compatibility with augmentation operations\n",
    "    image = image.astype(np.float32)\n",
    "\n",
    "    transform = A.Compose([\n",
    "        A.AdvancedBlur(p=0.5),\n",
    "        A.CLAHE(p=0.5),\n",
    "        A.Downscale(p=0.5),\n",
    "        A.Emboss(p=0.5),\n",
    "        A.Equalize(p=0.5),\n",
    "        A.FancyPCA(p=0.5),\n",
    "        A.GaussNoise(p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.5),\n",
    "        A.CoarseDropout(p=0.5),\n",
    "        A.PixelDropout(p=0.5)\n",
    "    ])\n",
    "    \n",
    "    augmented = transform(image=image)\n",
    "    return augmented['image']\n",
    "\n",
    "\n",
    "# Simulate training data (assuming a single 512x512 clean brain image)\n",
    "img_path = '61_processed_image_edit.png'\n",
    "image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Assuming grayscale MRI image\n",
    "image = cv2.resize(image, (512, 512))  # Resize to (512, 512)\n",
    "\n",
    "# Albumentations requires the input to have 3 channels, so expand dimensions\n",
    "image = np.expand_dims(image, axis=-1)\n",
    "image = image / 255.0  # Normalize\n",
    "\n",
    "# Build VAE model\n",
    "vae, encoder, decoder = build_vae(input_shape=(512, 512, 1))\n",
    "\n",
    "# Train the VAE\n",
    "epochs = 10000\n",
    "batch_size = 32\n",
    "\n",
    "# Modified inject_anomaly function to return both the augmented image and the distorted window\n",
    "# Modified inject_anomaly function to place random-shaped windows on the original image\n",
    "def inject_anomaly(image, window_size=200):\n",
    "    h, w = image.shape[:2]\n",
    "    # Select a random window area from the image\n",
    "    x, y = np.random.randint(0, h - window_size), np.random.randint(0, w - window_size)\n",
    "    anomaly_window = image[x:x+window_size, y:y+window_size]\n",
    "\n",
    "    # Apply contrast change and elastic deformation\n",
    "    anomaly_window = A.RandomBrightnessContrast(p=1.0, brightness_limit=(-.4,0.4), contrast_limit=(-0.6,0.6))(image=anomaly_window)[\"image\"]\n",
    "    anomaly_window = A.ElasticTransform(p=1.0, alpha=50, sigma=50)(image=anomaly_window)[\"image\"]\n",
    "\n",
    "    # Create a random mask (you can modify this to get different shapes)\n",
    "    mask = np.zeros_like(anomaly_window, dtype=np.uint8)\n",
    "    num_shapes = np.random.randint(1, 4)  # Number of shapes to create a random mask\n",
    "\n",
    "    for _ in range(num_shapes):\n",
    "        shape_type = np.random.choice(['ellipse', 'polygon'])\n",
    "        if shape_type == 'ellipse':\n",
    "            center = (np.random.randint(0, window_size), np.random.randint(0, window_size))\n",
    "            axes = (np.random.randint(10, window_size // 2), np.random.randint(10, window_size // 2))\n",
    "            angle = np.random.randint(0, 180)\n",
    "            cv2.ellipse(mask, center, axes, angle, 0, 360, (255, 255, 255), -1)\n",
    "        elif shape_type == 'polygon':\n",
    "            num_points = np.random.randint(3, 7)\n",
    "            points = np.array([[\n",
    "                (np.random.randint(0, window_size), np.random.randint(0, window_size))\n",
    "                for _ in range(num_points)\n",
    "            ]], dtype=np.int32)\n",
    "            cv2.fillPoly(mask, points, (255, 255, 255))\n",
    "\n",
    "    # Apply mask to the anomaly window\n",
    "    masked_anomaly = cv2.bitwise_and(anomaly_window, anomaly_window, mask=mask)\n",
    "\n",
    "    # Place the modified, random-shaped window back into the original image\n",
    "    anomaly_image = image.copy()\n",
    "    new_x, new_y = np.random.randint(0, h - window_size), np.random.randint(0, w - window_size)\n",
    "\n",
    "    # Insert the masked anomaly at the new location\n",
    "    window_region = anomaly_image[new_x:new_x+window_size, new_y:new_y+window_size]\n",
    "    np.copyto(window_region, masked_anomaly, where=mask.astype(bool))\n",
    "\n",
    "    return anomaly_image, masked_anomaly\n",
    "\n",
    "\n",
    "\n",
    "# Training loop with anomaly injection\n",
    "epochs = 10000\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(epochs + 1):\n",
    "    # Inject new anomaly every 500 epochs\n",
    "    if epoch % 500 == 0:\n",
    "        # Create a new augmented image with anomalies and capture the anomaly window\n",
    "        augmented_image, distorted_window = inject_anomaly(np.squeeze(image))\n",
    "        augmented_image = np.expand_dims(augmented_image, axis=-1)  # Add channel dimension\n",
    "        augmented_image = np.expand_dims(augmented_image, axis=0)  # Add batch dimension\n",
    "\n",
    "    # Train the model with the augmented image containing anomalies\n",
    "    # Ensure y (original image) has the correct batch and channel dimensions\n",
    "    target_image = np.expand_dims(image, axis=-1)  # Add channel dimension\n",
    "    target_image = np.expand_dims(target_image, axis=0)  # Add batch dimension\n",
    "    \n",
    "    # Train the model with the augmented image and the target image\n",
    "    vae.fit(augmented_image, target_image, epochs=1, batch_size=batch_size, verbose=1)\n",
    "\n",
    "\n",
    "    # Print and display outputs every 50 epochs\n",
    "    if epoch % 50 == 0:\n",
    "        reconstructed = vae.predict(np.expand_dims(image, axis=0))\n",
    "        reconstructed = np.squeeze(reconstructed)  # Remove the batch dimension\n",
    "\n",
    "        print(f\"Epoch: {epoch}\")\n",
    "        \n",
    "        # Display original, augmented, reconstructed images, and distorted window\n",
    "        fig, ax = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "        ax[0].imshow(np.squeeze(image), cmap='gray')\n",
    "        ax[0].set_title(\"Original Image\")\n",
    "        ax[0].axis(\"off\")\n",
    "\n",
    "        ax[1].imshow(np.squeeze(augmented_image), cmap='gray')\n",
    "        ax[1].set_title(\"Augmented with Anomaly\")\n",
    "        ax[1].axis(\"off\")\n",
    "\n",
    "        ax[2].imshow(reconstructed, cmap='gray')\n",
    "        ax[2].set_title(\"Reconstructed Image\")\n",
    "        ax[2].axis(\"off\")\n",
    "\n",
    "        ax[3].imshow(distorted_window, cmap='gray')\n",
    "        ax[3].set_title(\"Distorted Anomaly Window\")\n",
    "        ax[3].axis(\"off\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    # Save the model every 100 epochs\n",
    "    if epoch % 1000 == 0:\n",
    "        vae.save(f\"vae_model_epoch_{epoch}.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9d153e-9071-44d0-b1ee-aac7692debfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# Define the same VAE architecture used for saving the model\n",
    "def build_vae(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)  # 256x256\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)  # 128x128\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), padding='same')(x)  # 64x64\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    mu = layers.Dense(128)(x)\n",
    "    log_var = layers.Dense(128)(x)\n",
    "\n",
    "    def sampling(args):\n",
    "        mu, log_var = args\n",
    "        batch = tf.shape(mu)[0]\n",
    "        dim = tf.shape(mu)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return mu + tf.exp(0.5 * log_var) * epsilon\n",
    "\n",
    "    z = layers.Lambda(sampling)([mu, log_var])\n",
    "\n",
    "    # Decoder\n",
    "    decoder_input = layers.Input(shape=(128,))\n",
    "    x = layers.Dense(64 * 64 * 128, activation='relu')(decoder_input)\n",
    "    x = layers.Reshape((64, 64, 128))(x)\n",
    "    x = layers.Conv2DTranspose(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)  # 128x128\n",
    "    x = layers.Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)  # 256x256\n",
    "    x = layers.Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)  # 512x512\n",
    "\n",
    "    outputs = layers.Conv2DTranspose(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    encoder = Model(inputs, [z, mu, log_var], name='encoder')\n",
    "    decoder = Model(decoder_input, outputs, name='decoder')\n",
    "\n",
    "    vae_outputs = decoder(encoder(inputs)[0])\n",
    "    vae = Model(inputs, vae_outputs, name='vae')\n",
    "\n",
    "    return vae, encoder, decoder\n",
    "\n",
    "# Load the model\n",
    "vae, encoder, decoder = build_vae(input_shape=(512, 512, 1))\n",
    "vae.load_weights(\"vae_model_epoch_10000.h5\")  # Replace with the correct model path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff802073-9489-47d3-a8ec-87393ebf8097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the anomalous image in the same way as the clean image\n",
    "\n",
    "anomalous_img_path = 'test/processed_image_edit.png'\n",
    "anomalous_image = cv2.imread(anomalous_img_path, cv2.IMREAD_GRAYSCALE)\n",
    "anomalous_image = cv2.resize(anomalous_image, (512, 512))\n",
    "anomalous_image = anomalous_image / 255.0\n",
    "anomalous_image = np.expand_dims(np.expand_dims(anomalous_image, axis=0), axis=-1)\n",
    "\n",
    "\n",
    "# Predict and compute anomaly\n",
    "reconstructed_anomalous = vae.predict(anomalous_image)\n",
    "difference = np.abs(anomalous_image - reconstructed_anomalous)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Anomalous Image\")\n",
    "plt.imshow(np.squeeze(anomalous_image), cmap='gray')\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Reconstructed Clean Image\")\n",
    "plt.imshow(np.squeeze(reconstructed_anomalous), cmap='gray')\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Tumor Region (Difference)\")\n",
    "plt.imshow(np.squeeze(difference), cmap='hot')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd6507f-7a23-408a-a945-e9a9fa8f533e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load and preprocess the anomalous image in the same way as the clean image\n",
    "anomalous_img_path = 'test/processed_image_edit.png'\n",
    "anomalous_image = cv2.imread(anomalous_img_path, cv2.IMREAD_GRAYSCALE)\n",
    "anomalous_image = cv2.resize(anomalous_image, (512, 512))\n",
    "anomalous_image = anomalous_image / 255.0\n",
    "anomalous_image = np.expand_dims(np.expand_dims(anomalous_image, axis=0), axis=-1)\n",
    "\n",
    "# Predict and compute anomaly\n",
    "reconstructed_anomalous = vae.predict(anomalous_image)\n",
    "difference = np.abs(anomalous_image - reconstructed_anomalous)\n",
    "\n",
    "# Thresholding to create a binary mask\n",
    "threshold_value = 0.1  # Set a threshold value to identify anomaly\n",
    "binary_mask = difference > threshold_value  # Binary mask (True where difference > threshold)\n",
    "\n",
    "# Convert the mask to float for visualization purposes\n",
    "binary_mask = binary_mask.astype(np.float32)\n",
    "\n",
    "# Plot the anomalous image, reconstructed clean image, and the tumor region (binary mask)\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Anomalous Image\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Anomalous Image\")\n",
    "plt.imshow(np.squeeze(anomalous_image), cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "# Reconstructed Clean Image\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Reconstructed Clean Image\")\n",
    "plt.imshow(np.squeeze(reconstructed_anomalous), cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "# Tumor Region (Binary Mask)\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Tumor Region (Binary Mask)\")\n",
    "plt.imshow(np.squeeze(binary_mask), cmap='hot')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446a3095-9289-4f5e-a3a8-472b25744f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load and preprocess the anomalous image in the same way as the clean image\n",
    "anomalous_img_path = 'test/processed_image_edit.png'\n",
    "anomalous_image = cv2.imread(anomalous_img_path, cv2.IMREAD_GRAYSCALE)\n",
    "anomalous_image = cv2.resize(anomalous_image, (512, 512))\n",
    "anomalous_image = anomalous_image / 255.0\n",
    "anomalous_image = np.expand_dims(np.expand_dims(anomalous_image, axis=0), axis=-1)\n",
    "\n",
    "# Pass the image through the encoder to get the latent space (z, mu, log_var)\n",
    "z, mu, log_var = encoder.predict(anomalous_image)\n",
    "\n",
    "# Decode the latent representation (z) to reconstruct the clean image\n",
    "reconstructed_anomalous = decoder.predict(z)\n",
    "\n",
    "# Compute the difference between the original anomalous image and the reconstructed image\n",
    "difference = np.abs(anomalous_image - reconstructed_anomalous)\n",
    "\n",
    "# Thresholding to create a binary mask for the tumor region\n",
    "threshold_value = 0.2  # You can adjust this value\n",
    "binary_mask = difference > threshold_value\n",
    "binary_mask = binary_mask.astype(np.float32)\n",
    "\n",
    "# Visualize the original anomalous image, reconstructed clean image, and the tumor region (binary mask)\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Anomalous Image\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.title(\"Anomalous Image\")\n",
    "plt.imshow(np.squeeze(anomalous_image), cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "# Latent Space (mu)\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.title(\"Latent Space (mu)\")\n",
    "plt.plot(mu[0])  # Plot the latent space (mu) for visualization\n",
    "plt.axis('on')\n",
    "\n",
    "# Latent Space (log_var)\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.title(\"Latent Space (log_var)\")\n",
    "plt.plot(log_var[0])  # Plot the latent space (log_var) for visualization\n",
    "plt.axis('on')\n",
    "\n",
    "# Reconstructed Clean Image\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.title(\"Reconstructed Clean Image\")\n",
    "plt.imshow(np.squeeze(reconstructed_anomalous), cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "# Tumor Region (Difference)\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.title(\"Tumor Region (Difference)\")\n",
    "plt.imshow(np.squeeze(difference), cmap='hot')\n",
    "plt.axis('off')\n",
    "\n",
    "# Tumor Region (Binary Mask)\n",
    "plt.subplot(2, 3, 6)\n",
    "plt.title(\"Tumor Region (Binary Mask)\")\n",
    "plt.imshow(np.squeeze(binary_mask), cmap='hot')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e628ced6-4aab-4303-a034-13421c650f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Function to calculate reconstruction error\n",
    "def calculate_reconstruction_error(original, reconstructed):\n",
    "    return np.mean(np.square(original - reconstructed), axis=(1, 2, 3))  # MSE error per image\n",
    "\n",
    "# Function to classify as anomalous based on a threshold\n",
    "def classify_anomalies(reconstruction_error, threshold):\n",
    "    return reconstruction_error > threshold\n",
    "\n",
    "# Load test images (assuming grayscale 512x512 MRI images)\n",
    "def load_image(img_path):\n",
    "    image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    image = cv2.resize(image, (512, 512))\n",
    "    image = np.expand_dims(image, axis=-1)  # Add channel dimension\n",
    "    image = image / 255.0  # Normalize\n",
    "    return np.expand_dims(image, axis=0)  # Add batch dimension\n",
    "\n",
    "# Define a function to evaluate model performance and show reconstructed images\n",
    "def evaluate_model_and_display(vae, test_images, true_labels, threshold):\n",
    "    reconstruction_errors = []\n",
    "    predictions = []\n",
    "    \n",
    "    for img in test_images:\n",
    "        original = img\n",
    "        reconstructed = vae.predict(img)  # Predict reconstructed image\n",
    "        error = calculate_reconstruction_error(original, reconstructed)\n",
    "        reconstruction_errors.append(error)\n",
    "        predictions.append(classify_anomalies(error, threshold))\n",
    "    \n",
    "        # Display original and reconstructed images\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        \n",
    "        # Original image\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(np.squeeze(original), cmap='gray')\n",
    "        plt.title(\"Original Image\")\n",
    "        plt.axis(\"off\")\n",
    "\n",
    "        # Reconstructed image\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(np.squeeze(reconstructed), cmap='gray')\n",
    "        if classify_anomalies(error, threshold):\n",
    "            plt.title(\"Reconstructed Image (Anomalous)\")\n",
    "        else:\n",
    "            plt.title(\"Reconstructed Image (Normal)\")\n",
    "        plt.axis(\"off\")\n",
    "        \n",
    "        plt.show()\n",
    "    \n",
    "    reconstruction_errors = np.array(reconstruction_errors)\n",
    "    predictions = np.array(predictions)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    precision = precision_score(true_labels, predictions)\n",
    "    recall = recall_score(true_labels, predictions)\n",
    "    f1 = f1_score(true_labels, predictions)\n",
    "    roc_auc = roc_auc_score(true_labels, reconstruction_errors)\n",
    "\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1-Score: {f1}\")\n",
    "    print(f\"ROC-AUC: {roc_auc}\")\n",
    "\n",
    "    return predictions, reconstruction_errors\n",
    "\n",
    "# Example usage\n",
    "test_image_paths = ['test/processed_image_edit.png',r\"C:\\Users\\priya\\Documents\\DL project\\test 2\\processed_image_edit.png\",r\"C:\\Users\\priya\\Documents\\DL project\\test 3\\processed_image_edit.png\"]  # Replace with actual image paths\n",
    "test_images = [load_image(path) for path in test_image_paths]\n",
    "true_labels = [1, 0, 0]  # Ground truth labels (0 = normal, 1 = anomalous)\n",
    "\n",
    "# Load the saved VAE model\n",
    "vae, encoder, decoder = build_vae(input_shape=(512, 512, 1))\n",
    "vae.load_weights(\"vae_model_epoch_5000.h5\")  # Replace with the correct path\n",
    "\n",
    "# Set an anomaly threshold\n",
    "anomaly_threshold = 0.05  # You can tune this based on your validation results\n",
    "\n",
    "# Evaluate the model and display reconstructed images\n",
    "predictions, reconstruction_errors = evaluate_model_and_display(vae, test_images, true_labels, anomaly_threshold)\n",
    "\n",
    "# Plot the reconstruction errors\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(reconstruction_errors, label=\"Reconstruction Errors\")\n",
    "plt.axhline(y=anomaly_threshold, color='r', linestyle='--', label=\"Anomaly Threshold\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcef82b-3990-43e5-a2b2-9bf70dfa8dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "# Function to load an image\n",
    "def load_image(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Load as grayscale\n",
    "    image = cv2.resize(image, (512, 512))  # Resize to the required dimensions\n",
    "    return image / 255.0  # Normalize to [0, 1]\n",
    "\n",
    "# Function to compute SSIM map and score\n",
    "def compute_ssim_map(original, reconstructed):\n",
    "    ssim_map = ssim(original, reconstructed, full=True, data_range=1.0)[1]\n",
    "    ssim_score = np.mean(ssim_map)  # Average SSIM score\n",
    "    return ssim_map, ssim_score\n",
    "\n",
    "# Function to highlight anomalous regions based on SSIM\n",
    "def highlight_anomalous_regions(ssim_map, threshold):\n",
    "    # Create the anomaly mask\n",
    "    anomaly_mask = ssim_map < threshold\n",
    "    return anomaly_mask.astype(float)  # Ensure the mask is in float format for visualization\n",
    "\n",
    "# Function to visualize original, reconstructed, and anomaly mask\n",
    "def visualize_anomalous_regions(original, reconstructed, anomaly_mask):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Original image\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(original, cmap='gray')\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Anomaly mask\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(anomaly_mask, cmap='hot', alpha=0.6)  # Display anomalous regions using heatmap\n",
    "    plt.title(\"Anomalous Regions (SSIM < Threshold)\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    # Reconstructed image\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(reconstructed, cmap='gray')\n",
    "    plt.title(\"Reconstructed Image\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Function to evaluate model and display anomalies\n",
    "def evaluate_and_display_anomalies(vae, test_images, threshold_ssim):\n",
    "    for original in test_images:\n",
    "        original = np.expand_dims(original, axis=-1)  # Add channel dimension\n",
    "        original = np.expand_dims(original, axis=0)   # Add batch dimension\n",
    "\n",
    "        # Reconstruct the image\n",
    "        reconstructed = vae.predict(original)\n",
    "\n",
    "        # Compute SSIM map and score\n",
    "        ssim_map, ssim_score = compute_ssim_map(np.squeeze(original), np.squeeze(reconstructed))\n",
    "\n",
    "        # Highlight anomalous regions\n",
    "        anomaly_mask = highlight_anomalous_regions(ssim_map, threshold=threshold_ssim)\n",
    "\n",
    "        # Visualize the anomalies\n",
    "        visualize_anomalous_regions(np.squeeze(original), np.squeeze(reconstructed), anomaly_mask)\n",
    "\n",
    "# Example usage\n",
    "test_image_paths = [\n",
    "    'test/processed_image_edit.png', \n",
    "    r\"C:\\Users\\priya\\Documents\\DL project\\test 2\\processed_image_edit.png\",\n",
    "    r\"C:\\Users\\priya\\Documents\\DL project\\test 3\\processed_image_edit.png\"\n",
    "]  # Replace with actual image paths\n",
    "\n",
    "# Load test images\n",
    "test_images = [load_image(path) for path in test_image_paths]\n",
    "\n",
    "# Load the saved VAE model\n",
    "vae, encoder, decoder = build_vae(input_shape=(512, 512, 1))\n",
    "vae.load_weights(\"vae_model_epoch_5000.h5\")  # Replace with the correct path\n",
    "\n",
    "# Set SSIM threshold for anomaly detection\n",
    "ssim_threshold = 0.85  # Adjust this threshold based on your use case\n",
    "\n",
    "# Evaluate the model and display anomalies\n",
    "evaluate_and_display_anomalies(vae, test_images, threshold_ssim=ssim_threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca78a52-cb7d-40a7-9323-5d8a5f049e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load and preprocess the anomalous image in the same way as the clean image\n",
    "anomalous_img_path = 'test/processed_image_edit.png'  # Path to the uploaded anomalous image\n",
    "anomalous_image = cv2.imread(anomalous_img_path, cv2.IMREAD_GRAYSCALE)\n",
    "anomalous_image = cv2.resize(anomalous_image, (512, 512))\n",
    "anomalous_image = anomalous_image / 255.0\n",
    "anomalous_image = np.expand_dims(np.expand_dims(anomalous_image, axis=0), axis=-1)\n",
    "\n",
    "# Predict and compute anomaly using the pre-trained VAE model\n",
    "reconstructed_anomalous = vae.predict(anomalous_image)\n",
    "difference = np.abs(anomalous_image - reconstructed_anomalous)\n",
    "\n",
    "# Thresholding to create a binary mask\n",
    "threshold_value = 0.1  # Set a threshold value to identify anomaly\n",
    "binary_mask = difference > threshold_value  # Binary mask (True where difference > threshold)\n",
    "\n",
    "# Calculate the reconstruction error map (absolute difference)\n",
    "error_map = np.squeeze(difference)  # Removing extra dimensions for visualization\n",
    "\n",
    "# Normalize the error map for visualization\n",
    "normalized_error_map = (error_map - np.min(error_map)) / (np.max(error_map) - np.min(error_map))\n",
    "\n",
    "# Plot the anomalous image, reconstructed clean image, error heatmap, and the tumor region (binary mask)\n",
    "plt.figure(figsize=(16, 5))\n",
    "\n",
    "# Anomalous Image\n",
    "plt.subplot(1, 4, 1)\n",
    "plt.title(\"Anomalous Image\")\n",
    "plt.imshow(np.squeeze(anomalous_image), cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "# Reconstructed Clean Image\n",
    "plt.subplot(1, 4, 2)\n",
    "plt.title(\"Reconstructed Clean Image\")\n",
    "plt.imshow(np.squeeze(reconstructed_anomalous), cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "# Error Heatmap (Highlighting high reconstruction error regions)\n",
    "plt.subplot(1, 4, 3)\n",
    "plt.title(\"Reconstruction Error Heatmap\")\n",
    "plt.imshow(normalized_error_map, cmap='hot')  # 'hot' colormap for heatmap\n",
    "plt.axis('off')\n",
    "\n",
    "# Tumor Region (Binary Mask)\n",
    "plt.subplot(1, 4, 4)\n",
    "plt.title(\"Tumor Region (Binary Mask)\")\n",
    "plt.imshow(np.squeeze(binary_mask), cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9486e08b-7fac-4f1c-81bb-5a51451a2eac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9e4d01-34ef-4794-b41c-dee5360cccd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5612c757-4c4a-4995-8062-92f9e6587f43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5762332b-8e1b-4368-b445-140f6b69cdf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42136dbd-6c18-4028-9d86-587d5e51cd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to compute SSIM loss\n",
    "def ssim_loss(y_true, y_pred):\n",
    "    return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, max_val=1.0))\n",
    "\n",
    "# Build the GAN model\n",
    "def build_gan(input_shape):\n",
    "    # Generator model\n",
    "    generator_input = layers.Input(shape=(100,))\n",
    "    x = layers.Dense(64 * 64 * 128, activation='relu')(generator_input)\n",
    "    x = layers.Reshape((64, 64, 128))(x)\n",
    "    x = layers.Conv2DTranspose(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)  # 128x128\n",
    "    x = layers.Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)  # 256x256\n",
    "    x = layers.Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)  # 512x512\n",
    "\n",
    "    generator_output = layers.Conv2DTranspose(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    generator = Model(generator_input, generator_output, name='generator')\n",
    "\n",
    "    # Discriminator model\n",
    "    discriminator_input = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(discriminator_input)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    discriminator_output = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    discriminator = Model(discriminator_input, discriminator_output, name='discriminator')\n",
    "\n",
    "    # Compile the models\n",
    "    discriminator.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return generator, discriminator\n",
    "\n",
    "# Data augmentation using albumentations\n",
    "def augment_image(image):\n",
    "    # Convert to float32 for compatibility with augmentation operations\n",
    "    image = image.astype(np.float32)\n",
    "\n",
    "    transform = A.Compose([\n",
    "        A.AdvancedBlur(p=0.5),\n",
    "        A.CLAHE(p=0.5),\n",
    "        A.Downscale(p=0.5),\n",
    "        A.Emboss(p=0.5),\n",
    "        A.Equalize(p=0.5),\n",
    "        A.FancyPCA(p=0.5),\n",
    "        A.GaussNoise(p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.5),\n",
    "        A.CoarseDropout(p=0.5),\n",
    "        A.PixelDropout(p=0.5)\n",
    "    ])\n",
    "    \n",
    "    augmented = transform(image=image)\n",
    "    return augmented['image']\n",
    "\n",
    "# Simulate training data (assuming a single 512x512 clean brain image)\n",
    "img_path = '61_processed_image_edit.png'\n",
    "image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Assuming grayscale MRI image\n",
    "image = cv2.resize(image, (512, 512))  # Resize to (512, 512)\n",
    "\n",
    "# Albumentations requires the input to have 3 channels, so expand dimensions\n",
    "image = np.expand_dims(image, axis=-1)\n",
    "image = image / 255.0  # Normalize\n",
    "\n",
    "# Build GAN model\n",
    "generator, discriminator = build_gan(input_shape=(512, 512, 1))\n",
    "\n",
    "# Training loop with anomaly injection\n",
    "epochs = 1000\n",
    "batch_size = 32\n",
    "\n",
    "# Modified inject_anomaly function to place random-shaped windows on the original image\n",
    "def inject_anomaly(image, window_size=200):\n",
    "    h, w = image.shape[:2]\n",
    "    # Create a new image to avoid modifying the original\n",
    "    anomaly_image = image.copy()\n",
    "    \n",
    "    for _ in range(32):  # Create 32 anomalies for the batch\n",
    "        # Select a random window area from the image\n",
    "        x, y = np.random.randint(0, h - window_size), np.random.randint(0, w - window_size)\n",
    "        anomaly_window = anomaly_image[x:x + window_size, y:y + window_size]\n",
    "\n",
    "        # Apply contrast change and elastic deformation\n",
    "        anomaly_window = A.RandomBrightnessContrast(p=1.0, brightness_limit=(-.4, 0.4), contrast_limit=(-0.6, 0.6))(image=anomaly_window)[\"image\"]\n",
    "        anomaly_window = A.ElasticTransform(p=0.7, alpha=50, sigma=50)(image=anomaly_window)[\"image\"]\n",
    "\n",
    "        # Create a random mask\n",
    "        mask = np.zeros_like(anomaly_window, dtype=np.uint8)\n",
    "        num_shapes = np.random.randint(1, 4)  # Number of shapes to create a random mask\n",
    "\n",
    "        for _ in range(num_shapes):\n",
    "            shape_type = np.random.choice(['ellipse', 'polygon'])\n",
    "            if shape_type == 'ellipse':\n",
    "                center = (np.random.randint(0, window_size), np.random.randint(0, window_size))\n",
    "                axes = (np.random.randint(10, window_size // 2), np.random.randint(10, window_size // 2))\n",
    "                angle = np.random.randint(0, 180)\n",
    "                cv2.ellipse(mask, center, axes, angle, 0, 360, (255, 255, 255), -1)\n",
    "            elif shape_type == 'polygon':\n",
    "                num_points = np.random.randint(3, 7)\n",
    "                points = np.array([[\n",
    "                    (np.random.randint(0, window_size), np.random.randint(0, window_size))\n",
    "                    for _ in range(num_points)\n",
    "                ]], dtype=np.int32)\n",
    "                cv2.fillPoly(mask, points, (255, 255, 255))\n",
    "\n",
    "        # Apply mask to the anomaly window\n",
    "        masked_anomaly = cv2.bitwise_and(anomaly_window, anomaly_window, mask=mask)\n",
    "\n",
    "        # Place the modified, random-shaped window back into the original image\n",
    "        window_region = anomaly_image[x:x + window_size, y:y + window_size]\n",
    "        np.copyto(window_region, masked_anomaly, where=mask.astype(bool))\n",
    "\n",
    "    return anomaly_image  # Return the entire batch of anomalies\n",
    "\n",
    "# Training the GAN\n",
    "for epoch in range(epochs + 1):\n",
    "    # Inject new anomalies every 500 epochs\n",
    "    if epoch % 500 == 0:\n",
    "        # Create a new augmented image with anomalies\n",
    "        # Create a new augmented image with anomalies\n",
    "        augmented_image = inject_anomaly(np.squeeze(image))  # Now it's the entire image with anomalies\n",
    "        \n",
    "        # Expand dimensions and replicate the augmented image to create a batch of size 32\n",
    "        augmented_images = np.expand_dims(augmented_image, axis=0)\n",
    "        augmented_images = np.repeat(augmented_images, batch_size, axis=0)  # Shape should be (32, 512, 512, 1)\n",
    "\n",
    "\n",
    "    # Generate random noise for generator input\n",
    "    noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "    \n",
    "    # Generate images using the generator\n",
    "    generated_images = generator.predict(noise)\n",
    "\n",
    "    # Prepare real and fake labels\n",
    "    real_labels = np.ones((batch_size, 1))\n",
    "    fake_labels = np.zeros((batch_size, 1))\n",
    "\n",
    "    # Train discriminator\n",
    "    discriminator_loss_real = discriminator.train_on_batch(augmented_images, real_labels)\n",
    "    discriminator_loss_fake = discriminator.train_on_batch(generated_images, fake_labels)\n",
    "    discriminator_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n",
    "\n",
    "    # Train generator\n",
    "    noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "    generator_loss = discriminator.train_on_batch(generator.predict(noise), real_labels)\n",
    "\n",
    "    # Print and display outputs every 50 epochs\n",
    "    if epoch % 50 == 0:\n",
    "        reconstructed = generator.predict(noise)\n",
    "        reconstructed = np.squeeze(reconstructed)  # Remove the batch dimension\n",
    "\n",
    "        print(f\"Epoch: {epoch}, Discriminator Loss: {discriminator_loss[0]}, Generator Loss: {generator_loss}\")\n",
    "\n",
    "        # Display original, augmented, reconstructed images\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "        ax[0].imshow(np.squeeze(image), cmap='gray')\n",
    "        ax[0].set_title(\"Original Image\")\n",
    "        ax[0].axis(\"off\")\n",
    "\n",
    "        ax[1].imshow(np.squeeze(augmented_image), cmap='gray')\n",
    "        ax[1].set_title(\"Augmented with Anomaly\")\n",
    "        ax[1].axis(\"off\")\n",
    "\n",
    "        ax[2].imshow(reconstructed[0], cmap='gray')\n",
    "        ax[2].set_title(\"Generated Image\")\n",
    "        ax[2].axis(\"off\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    # Save the models every 1000 epochs\n",
    "    if epoch % 1000 == 0:\n",
    "        generator.save(f\"generator_epoch_{epoch}.h5\")\n",
    "        discriminator.save(f\"discriminator_epoch_{epoch}.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90158098-f8ec-46c4-be3a-9f8deb482276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to compute SSIM loss\n",
    "def ssim_loss(y_true, y_pred):\n",
    "    return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, max_val=1.0))\n",
    "\n",
    "# Build the GAN model\n",
    "def build_gan(input_shape):\n",
    "    # Generator model\n",
    "    generator_input = layers.Input(shape=(100,))\n",
    "    x = layers.Dense(64 * 64 * 128, activation='relu')(generator_input)\n",
    "    x = layers.Reshape((64, 64, 128))(x)\n",
    "    x = layers.Conv2DTranspose(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)  # 128x128\n",
    "    x = layers.Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)  # 256x256\n",
    "    x = layers.Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.UpSampling2D((2, 2))(x)  # 512x512\n",
    "\n",
    "    generator_output = layers.Conv2DTranspose(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "    generator = Model(generator_input, generator_output, name='generator')\n",
    "\n",
    "    # Discriminator model\n",
    "    discriminator_input = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(discriminator_input)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    discriminator_output = layers.Dense(1, activation='sigmoid')(x)\n",
    "    discriminator = Model(discriminator_input, discriminator_output, name='discriminator')\n",
    "\n",
    "    # Compile the discriminator with a smaller learning rate\n",
    "    discriminator.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "                          loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return generator, discriminator\n",
    "\n",
    "# Data augmentation using albumentations\n",
    "def augment_image(image):\n",
    "    transform = A.Compose([\n",
    "        A.AdvancedBlur(p=0.5),\n",
    "        A.CLAHE(p=0.5),\n",
    "        A.Downscale(p=0.5),\n",
    "        A.Emboss(p=0.5),\n",
    "        A.Equalize(p=0.5),\n",
    "        A.FancyPCA(p=0.5),\n",
    "        A.GaussNoise(p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.5),\n",
    "        A.CoarseDropout(p=0.5),\n",
    "        A.PixelDropout(p=0.5)\n",
    "    ])\n",
    "    augmented = transform(image=image)\n",
    "    return augmented['image']\n",
    "\n",
    "# Simulate training data (assuming a single 512x512 clean brain image)\n",
    "img_path = '61_processed_image_edit.png'\n",
    "image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Assuming grayscale MRI image\n",
    "image = cv2.resize(image, (512, 512))  # Resize to (512, 512)\n",
    "image = np.expand_dims(image, axis=-1) / 255.0  # Normalize\n",
    "\n",
    "# Build GAN model\n",
    "generator, discriminator = build_gan(input_shape=(512, 512, 1))\n",
    "\n",
    "# Training loop with anomaly injection\n",
    "epochs = 25000\n",
    "batch_size = 32\n",
    "\n",
    "# Modified inject_anomaly function to place random-shaped windows on the original image\n",
    "def inject_anomaly(image, window_size=200):\n",
    "    h, w = image.shape[:2]\n",
    "    anomaly_image = image.copy()\n",
    "    \n",
    "    for _ in range(32):  # Create 32 anomalies for the batch\n",
    "        x, y = np.random.randint(0, h - window_size), np.random.randint(0, w - window_size)\n",
    "        anomaly_window = anomaly_image[x:x + window_size, y:y + window_size]\n",
    "        anomaly_window = A.RandomBrightnessContrast(p=1.0, brightness_limit=(-.4, 0.4), contrast_limit=(-0.6, 0.6))(image=anomaly_window)[\"image\"]\n",
    "        anomaly_window = A.ElasticTransform(p=0.7, alpha=50, sigma=50)(image=anomaly_window)[\"image\"]\n",
    "        \n",
    "        mask = np.zeros_like(anomaly_window, dtype=np.uint8)\n",
    "        num_shapes = np.random.randint(1, 4)\n",
    "        \n",
    "        for _ in range(num_shapes):\n",
    "            shape_type = np.random.choice(['ellipse', 'polygon'])\n",
    "            if shape_type == 'ellipse':\n",
    "                center = (np.random.randint(0, window_size), np.random.randint(0, window_size))\n",
    "                axes = (np.random.randint(10, window_size // 2), np.random.randint(10, window_size // 2))\n",
    "                angle = np.random.randint(0, 180)\n",
    "                cv2.ellipse(mask, center, axes, angle, 0, 360, (255, 255, 255), -1)\n",
    "            elif shape_type == 'polygon':\n",
    "                points = np.array([[ (np.random.randint(0, window_size), np.random.randint(0, window_size)) for _ in range(np.random.randint(3, 7))]], dtype=np.int32)\n",
    "                cv2.fillPoly(mask, points, (255, 255, 255))\n",
    "        \n",
    "        masked_anomaly = cv2.bitwise_and(anomaly_window, anomaly_window, mask=mask)\n",
    "        window_region = anomaly_image[x:x + window_size, y:y + window_size]\n",
    "        np.copyto(window_region, masked_anomaly, where=mask.astype(bool))\n",
    "    \n",
    "    return anomaly_image\n",
    "\n",
    "# Training the GAN\n",
    "for epoch in range(epochs + 1):\n",
    "    if epoch % 500 == 0:\n",
    "        augmented_image = inject_anomaly(np.squeeze(image))\n",
    "        augmented_images = np.expand_dims(augmented_image, axis=0)\n",
    "        augmented_images = np.repeat(augmented_images, batch_size, axis=0)\n",
    "        augmented_images += 0.05 * np.random.normal(0, 1, augmented_images.shape)\n",
    "\n",
    "    noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "    generated_images = generator.predict(noise)\n",
    "    generated_images += 0.05 * np.random.normal(0, 1, generated_images.shape)\n",
    "\n",
    "    real_labels = 0.9 * np.ones((batch_size, 1))  # Label smoothing\n",
    "    fake_labels = np.zeros((batch_size, 1))\n",
    "\n",
    "    discriminator_loss_real = discriminator.train_on_batch(augmented_images, real_labels)\n",
    "    discriminator_loss_fake = discriminator.train_on_batch(generated_images, fake_labels)\n",
    "    discriminator_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n",
    "\n",
    "    for _ in range(2):  # Update generator twice\n",
    "        noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "        generator_loss = discriminator.train_on_batch(generator.predict(noise), real_labels)\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        reconstructed = generator.predict(noise)\n",
    "        reconstructed = np.squeeze(reconstructed)\n",
    "\n",
    "        print(f\"Epoch: {epoch}, Discriminator Loss: {discriminator_loss[0]}, Generator Loss: {generator_loss}\")\n",
    "\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        ax[0].imshow(np.squeeze(image), cmap='gray')\n",
    "        ax[0].set_title(\"Original Image\")\n",
    "        ax[0].axis(\"off\")\n",
    "        ax[1].imshow(np.squeeze(augmented_image), cmap='gray')\n",
    "        ax[1].set_title(\"Augmented with Anomaly\")\n",
    "        ax[1].axis(\"off\")\n",
    "        ax[2].imshow(reconstructed[0], cmap='gray')\n",
    "        ax[2].set_title(\"Generated Image\")\n",
    "        ax[2].axis(\"off\")\n",
    "        plt.show()\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        generator.save(f\"generator_epoch_{epoch}.h5\")\n",
    "        discriminator.save(f\"discriminator_epoch_{epoch}.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734a9b74-3021-4691-8f4d-0011e9252780",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
