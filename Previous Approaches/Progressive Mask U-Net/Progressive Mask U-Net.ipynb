{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4071155b-7934-4a0f-a1e5-e7c6415b6272",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LambdaCallback\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.image import ssim\n",
    "\n",
    "# Load the clean brain image\n",
    "image_path = r\"C:\\Users\\priya\\Documents\\DL project\\61_processed_image.png\"  # Path to the clean image\n",
    "brain_image = io.imread(image_path, as_gray=True)\n",
    "brain_image = np.expand_dims(brain_image, axis=-1)  # Add channel dimension\n",
    "#brain_image = brain_image / 255.0  # Normalize to [0,1]\n",
    "\n",
    "# Function to apply mask to the image, hiding part of it\n",
    "def mask_image(image, mask_center_x, mask_center_y, mask_size=100):\n",
    "    masked_image = np.copy(image)\n",
    "    masked_image[mask_center_x - mask_size:mask_center_x + mask_size,\n",
    "                 mask_center_y - mask_size:mask_center_y + mask_size] = 0\n",
    "    return masked_image\n",
    "\n",
    "# Visualize masked area\n",
    "def visualize_mask(image, mask_center_x, mask_center_y, mask_size=100):\n",
    "    masked_image = mask_image(image, mask_center_x, mask_center_y, mask_size)\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    ax[0].imshow(image[:, :, 0], cmap='gray')\n",
    "    ax[0].set_title(\"Original Image\")\n",
    "    ax[1].imshow(masked_image[:, :, 0], cmap='gray')\n",
    "    ax[1].set_title(f\"Masked Area at ({mask_center_x},{mask_center_y})\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def attention_block(input_tensor, filters):\n",
    "    attention = layers.Conv2D(filters, (1, 1), activation='sigmoid')(input_tensor)\n",
    "    return layers.multiply([input_tensor, attention])\n",
    "\n",
    "# Encoder Block\n",
    "def encoder_block(input_tensor, filters, use_attention=False):\n",
    "    x = layers.Conv2D(filters, (3, 3), activation='relu', padding='same')(input_tensor)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    if use_attention:\n",
    "        x = attention_block(x, filters)\n",
    "    x = layers.Conv2D(filters, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    skip = x\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "    return x, skip\n",
    "\n",
    "# Decoder Block\n",
    "def decoder_block(input_tensor, skip_tensor, filters, use_attention=False):\n",
    "    x = layers.Conv2DTranspose(filters, (2, 2), strides=(2, 2), padding='same')(input_tensor)\n",
    "    x = layers.concatenate([x, skip_tensor])\n",
    "    x = layers.Conv2D(filters, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    if use_attention:\n",
    "        x = attention_block(x, filters)\n",
    "    x = layers.Conv2D(filters, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    return x\n",
    "\n",
    "# UNet Model with Attention\n",
    "def build_unet(input_shape=(512, 512, 1)):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    \n",
    "    # Encoder\n",
    "    x1, skip1 = encoder_block(inputs, 64, use_attention=True)\n",
    "    x2, skip2 = encoder_block(x1, 128, use_attention=True)\n",
    "    x3, skip3 = encoder_block(x2, 256, use_attention=False)\n",
    "    \n",
    "    # Bottleneck\n",
    "    bottleneck = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(x3)\n",
    "    bottleneck = layers.BatchNormalization()(bottleneck)\n",
    "    bottleneck = layers.Dropout(0.3)(bottleneck)\n",
    "\n",
    "    # Decoder\n",
    "    x = decoder_block(bottleneck, skip3, 256, use_attention=False)\n",
    "    x = decoder_block(x, skip2, 128, use_attention=True)\n",
    "    x = decoder_block(x, skip1, 64, use_attention=True)\n",
    "\n",
    "    # Output Layer (Reconstructed Image)\n",
    "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(x)\n",
    "    \n",
    "    return models.Model(inputs, outputs)\n",
    "\n",
    "# Custom Loss Function (Weighted SSIM + MSE)\n",
    "def combined_loss(alpha=0.2):\n",
    "    def loss(y_true, y_pred):\n",
    "        mse_loss = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "        ssim_loss = 1 - tf.reduce_mean(ssim(y_true, y_pred, max_val=1.0))\n",
    "        return alpha * mse_loss + (1 - alpha) * ssim_loss\n",
    "    return loss\n",
    "\n",
    "# Callback to display reconstructed image every 50 epochs\n",
    "class DisplayReconstructedImage(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, image, output_path=\"reconstructed_image.png\", interval=50):\n",
    "        super().__init__()\n",
    "        self.image = image\n",
    "        self.interval = interval\n",
    "        self.output_path = output_path\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % self.interval == 0:\n",
    "            # Use self.model directly (assigned by Keras)\n",
    "            reconstructed_image = self.model.predict(self.image)\n",
    "            self.display_image(reconstructed_image, epoch)\n",
    "    \n",
    "    def display_image(self, reconstructed_image, epoch):\n",
    "        plt.figure(figsize=(5, 5))\n",
    "        plt.imshow(reconstructed_image[0, :, :, 0], cmap='gray')\n",
    "        plt.title(f\"Reconstructed Image at Epoch {epoch+1}\")\n",
    "        plt.axis('off')\n",
    "        plt.savefig(f\"reconstructed_epoch_{epoch+1}.png\")  # Save image for visual inspection\n",
    "        plt.show()\n",
    "\n",
    "# Compile the model\n",
    "# SSIM Metric\n",
    "def ssim_metric(y_true, y_pred):\n",
    "    return tf.reduce_mean(ssim(y_true, y_pred, max_val=1.0))\n",
    "\n",
    "# Compile the model\n",
    "input_shape = (512, 512, 1)\n",
    "unet_model = build_unet(input_shape)\n",
    "unet_model.compile(optimizer='adam', \n",
    "                   loss=combined_loss(alpha=0.8), \n",
    "                   metrics=[ssim_metric])\n",
    "\n",
    "\n",
    "# Checkpoint callback to save the model every 100 epochs\n",
    "checkpoint_cb = ModelCheckpoint(\"unet_attention_model.keras\", save_freq=100 * (len(brain_image) // 1), save_best_only=True)\n",
    "\n",
    "# Function to visualize the reconstruction and masked region\n",
    "def show_reconstruction(epoch, logs, masked_brain_image):\n",
    "    if epoch % 50 == 0:\n",
    "        reconstructed_img = unet_model.predict(np.expand_dims(masked_brain_image, axis=0))[0, :, :, 0]\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        ax[0].imshow(masked_brain_image[:, :, 0], cmap='gray')\n",
    "        ax[0].set_title(f\"Masked Input at Epoch {epoch}\")\n",
    "        ax[1].imshow(reconstructed_img, cmap='gray')\n",
    "        ax[1].set_title(f\"Reconstructed Image Epoch {epoch}\")\n",
    "        ax[2].imshow(brain_image[:, :, 0], cmap='gray')\n",
    "        ax[2].set_title(f\"Original Image\")\n",
    "        plt.show()\n",
    "\n",
    "# Function to progressively mask the image and train\n",
    "def progressive_training(model, brain_image, epochs_per_mask=500):\n",
    "    mask_centers = [\n",
    "    (100, 180), (120, 180), (140, 180), (160, 180), (200, 180), (220, 180),(240, 180), (260, 180), (332, 180),  # Top row\n",
    "    (100, 256), (120, 256), (140, 256), (160, 256), (200, 256), (220, 256),(240, 256), (260, 256), (332, 256),  # Top row\n",
    "    (100, 332), (120, 332), (140, 332), (160, 332), (200, 332), (220, 332),(240, 332), (260, 332), (332, 332),  # Top row\n",
    "]\n",
    "  # Predefined mask centers\n",
    "    for center_x, center_y in mask_centers:\n",
    "        masked_brain_image = mask_image(brain_image, center_x, center_y, mask_size=5)\n",
    "        \n",
    "        # Visualize the current masked region\n",
    "        visualize_mask(brain_image, center_x, center_y, mask_size=50)\n",
    "        \n",
    "        print(f\"Training on masked image with mask at center ({center_x}, {center_y})\")\n",
    "        \n",
    "        # Callback for visualizing the reconstruction at the current mask\n",
    "        reconstruction_cb = LambdaCallback(on_epoch_end=lambda epoch, logs: show_reconstruction(epoch, logs, masked_brain_image))\n",
    "        \n",
    "        # Train on the masked image\n",
    "        model.fit(\n",
    "            x=np.expand_dims(masked_brain_image, axis=0),\n",
    "            y=np.expand_dims(brain_image, axis=0),  # The target is the original clean brain image\n",
    "            epochs=epochs_per_mask,\n",
    "            callbacks=[checkpoint_cb, reconstruction_cb]\n",
    "        )\n",
    "        # After the model has learned to reconstruct the masked region, we move on to the next mask\n",
    "\n",
    "# Start progressive training\n",
    "progressive_training(unet_model, brain_image, epochs_per_mask=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc97b33e-bd90-457e-a347-887aa50717e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "unet_model.save('jaadu2.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe335d0-e6c2-44ec-aa4d-ed3daab2ab48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import jaccard_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.image import ssim\n",
    "\n",
    "def ssim_metric(y_true, y_pred):\n",
    "    return tf.reduce_mean(ssim(y_true, y_pred, max_val=1.0))\n",
    "# Load the trained model\n",
    "unet_model = tf.keras.models.load_model('jaadu2.keras',custom_objects={'loss': combined_loss(alpha=0.8), 'ssim_metric': ssim_metric})\n",
    "\n",
    "# Load the anomaly brain image and the segmentation mask\n",
    "anomaly_image_path = r\"C:\\Users\\priya\\Documents\\DL project\\test\\processed_image.png\"  # Replace with your actual path\n",
    "segment_mask_path = r\"C:\\Users\\priya\\Documents\\DL project\\test\\processed_mask.png\"  # Replace with your actual path\n",
    "\n",
    "# Load images\n",
    "anomaly_image = cv2.imread(anomaly_image_path, cv2.IMREAD_GRAYSCALE)\n",
    "segment_mask = cv2.imread(segment_mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Preprocess the anomaly image: expand dimensions to fit the model's input shape (batch size, height, width, channels)\n",
    "anomaly_image_exp = np.expand_dims(anomaly_image, axis=(0, -1))  # Add batch and channel dimensions\n",
    "\n",
    "# Ensure the segmentation mask is binary (threshold to create binary mask)\n",
    "segment_mask = (segment_mask > 0).astype(np.uint8)\n",
    "\n",
    "# Predict the clean brain image by reconstructing the anomaly image\n",
    "reconstructed_image = unet_model.predict(anomaly_image_exp)\n",
    "reconstructed_image = np.squeeze(reconstructed_image)  # Remove batch dimension for visualization\n",
    "\n",
    "# Difference between the original (anomaly) and reconstructed image\n",
    "predicted_diff = np.abs(anomaly_image - reconstructed_image)\n",
    "\n",
    "# Threshold the difference to get a binary mask for predicted anomaly\n",
    "threshold = 0.4 * np.max(predicted_diff)  # Adjust based on sensitivity\n",
    "predicted_segment = (predicted_diff > threshold).astype(np.uint8)\n",
    "\n",
    "# Flatten both the predicted mask and the ground truth mask for metric calculation\n",
    "predicted_segment_flat = predicted_segment.flatten()\n",
    "segment_mask_flat = segment_mask.flatten()\n",
    "\n",
    "# Compute the Intersection over Union (IoU) or Jaccard Index\n",
    "iou = jaccard_score(segment_mask_flat, predicted_segment_flat, average='binary')\n",
    "\n",
    "# Compute Dice coefficient (F1 score for binary segmentation)\n",
    "dice = f1_score(segment_mask_flat, predicted_segment_flat, average='binary')\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"IoU (Jaccard Index): {iou}\")\n",
    "print(f\"Dice Coefficient: {dice}\")\n",
    "\n",
    "# Visualize the original image, segment mask, reconstructed image, and predicted segment area\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "# Display the original anomaly brain image\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(anomaly_image, cmap='gray')\n",
    "plt.title('Original Anomaly Brain Image')\n",
    "plt.axis('off')\n",
    "\n",
    "# Display the ground truth segmentation mask\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.imshow(segment_mask, cmap='gray')\n",
    "plt.title('Ground Truth Segment Mask')\n",
    "plt.axis('off')\n",
    "\n",
    "# Display the reconstructed brain image (model output)\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.imshow(reconstructed_image, cmap='gray')\n",
    "plt.title('Reconstructed Clean Brain Image')\n",
    "plt.axis('off')\n",
    "\n",
    "# Display the predicted segment mask from the difference\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.imshow(predicted_segment, cmap='gray')\n",
    "plt.title('Predicted Segment Mask')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c2de0b-45b0-4a8a-a6a8-88d3f7393dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
