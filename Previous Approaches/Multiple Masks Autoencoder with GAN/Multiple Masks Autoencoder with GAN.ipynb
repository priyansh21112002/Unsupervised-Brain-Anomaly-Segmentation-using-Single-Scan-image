{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "En3ESMoCYXzQ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "import numpy as np\n",
    "\n",
    "# Load and reshape the image\n",
    "def load_image(image_path):\n",
    "    # Load the image directly without normalization\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_png(img, channels=1)  # Load as grayscale\n",
    "    img = tf.image.resize(img, [512, 512])  # Ensure it's 512x512\n",
    "    img = tf.expand_dims(img, axis=0)  # Add batch dimension\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0K7ycn7qYhQk"
   },
   "outputs": [],
   "source": [
    "def attention_block(x, filters):\n",
    "    # f and g reduce the number of filters\n",
    "    f = layers.Conv2D(filters // 8, (1, 1), strides=(1, 1), padding='same')(x)\n",
    "    g = layers.Conv2D(filters // 8, (1, 1), strides=(1, 1), padding='same')(x)\n",
    "    h = layers.Conv2D(filters, (1, 1), strides=(1, 1), padding='same')(x)\n",
    "\n",
    "    # Calculate attention map\n",
    "    attention = layers.Add()([f, g])  # Element-wise sum\n",
    "    attention = layers.Conv2D(filters, (1, 1), padding='same')(attention)  # Match filter count\n",
    "    attention = layers.Activation('softmax')(attention)\n",
    "\n",
    "    # Apply attention to the feature map\n",
    "    out = layers.Multiply()([attention, h])\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def build_autoencoder(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Encoder with attention\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = attention_block(x, 64)\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = attention_block(x, 128)\n",
    "\n",
    "    # Bottleneck\n",
    "    latent = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    latent = attention_block(latent, 256)\n",
    "\n",
    "    # Decoder\n",
    "    x = layers.Conv2DTranspose(128, (3, 3), activation='relu', padding='same')(latent)\n",
    "    x = layers.Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    outputs = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "# Autoencoder input shape is 512x512x1 (grayscale)\n",
    "autoencoder = build_autoencoder((512, 512, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T4IDKRKRYz2V"
   },
   "outputs": [],
   "source": [
    "# Define GAN generator\n",
    "def build_gan_generator(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "\n",
    "    latent = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "\n",
    "    x = layers.Conv2DTranspose(128, (3, 3), activation='relu', padding='same')(latent)\n",
    "    x = layers.Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)\n",
    "\n",
    "    outputs = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "# Generator input shape is the masked region (4x4)\n",
    "gan_generator = build_gan_generator((4, 4, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qy05y6MWY3g2"
   },
   "outputs": [],
   "source": [
    "# Define GAN discriminator\n",
    "def build_discriminator(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    x = layers.Conv2D(64, (3, 3), strides=2, activation='relu', padding='same')(inputs)\n",
    "    x = layers.Conv2D(128, (3, 3), strides=2, activation='relu', padding='same')(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)  # Output real/fake\n",
    "\n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "# Discriminator input shape is the masked region (4x4)\n",
    "discriminator = build_discriminator((4, 4, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zDtS_SCyY5J0"
   },
   "outputs": [],
   "source": [
    "# Loss functions (SSIM + MSE)\n",
    "def ssim_loss(y_true, y_pred):\n",
    "    return 1 - tf.reduce_mean(tf.image.ssim(y_true, y_pred, max_val=1.0))\n",
    "\n",
    "def combined_loss(y_true, y_pred, alpha=0.8):\n",
    "    mse_loss = tf.reduce_mean(tf.keras.losses.MSE(y_true, y_pred))\n",
    "    return alpha * mse_loss + (1 - alpha) * ssim_loss(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cvpQi8n3Y5--"
   },
   "outputs": [],
   "source": [
    "# Masking function remains unchanged\n",
    "def mask_image(image, mask_size=10):\n",
    "    mask = np.ones(image.shape)\n",
    "    for i in range(0, image.shape[1], mask_size):\n",
    "        for j in range(0, image.shape[2], mask_size):\n",
    "            if np.random.rand() > 0.5:  # Randomly select blocks to mask\n",
    "                mask[:, i:i+mask_size, j:j+mask_size, :] = 0\n",
    "    return image * mask  # Return masked image\n",
    "\n",
    "\n",
    "# Training loop\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_images(original_image, masked_image, ae_output, gan_input, gan_output, epoch):\n",
    "    \"\"\"\n",
    "    Display and save original image, input to autoencoder, input to GAN (masked), and their respective outputs.\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(1, 5, figsize=(20, 5))\n",
    "\n",
    "    # Convert tensors to numpy arrays for displaying\n",
    "    original_image_np = original_image.numpy()\n",
    "    masked_image_np = masked_image.numpy()\n",
    "    ae_output_np = ae_output.numpy()\n",
    "    gan_input_np = gan_input.numpy()\n",
    "    gan_output_np = gan_output.numpy()\n",
    "\n",
    "    # Original Image\n",
    "    axs[0].imshow(original_image_np[0].squeeze(), cmap='gray')\n",
    "    axs[0].set_title('Original Image')\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    # Autoencoder Input (entire clean image)\n",
    "    axs[1].imshow(masked_image_np[0].squeeze(), cmap='gray')\n",
    "    axs[1].set_title('Autoencoder Input (Masked)')\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    # Autoencoder Output\n",
    "    axs[2].imshow(ae_output_np[0].squeeze(), cmap='gray')\n",
    "    axs[2].set_title('Autoencoder Output')\n",
    "    axs[2].axis('off')\n",
    "\n",
    "    # GAN Input (Masked region)\n",
    "    axs[3].imshow(gan_input_np[0].squeeze(), cmap='gray')\n",
    "    axs[3].set_title('GAN Input (Masked Region)')\n",
    "    axs[3].axis('off')\n",
    "\n",
    "    # GAN Output (Reconstructed masked region)\n",
    "    axs[4].imshow(gan_output_np[0].squeeze(), cmap='gray')\n",
    "    axs[4].set_title('GAN Output')\n",
    "    axs[4].axis('off')\n",
    "\n",
    "    # Save the figure\n",
    "    plt.savefig(f\"outputs/training_epoch_{epoch}.png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def train(autoencoder, generator, discriminator, image, epochs=10000, save_interval=100):\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "\n",
    "    # Store the original image for comparison\n",
    "    original_image = tf.convert_to_tensor(image)  # Assuming the image is loaded as a NumPy array\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Generate mask and apply to the image\n",
    "            masked_image = mask_image(image)\n",
    "\n",
    "            # Autoencoder forward pass with masked image\n",
    "            ae_output = autoencoder(masked_image)\n",
    "\n",
    "            # Autoencoder loss: comparing reconstructed image with the original (unmasked) image\n",
    "            ae_loss = combined_loss(original_image, ae_output)  # SSIM + MSE with the original image\n",
    "\n",
    "            # Select a random region for GAN (example: middle region 128:132 is masked)\n",
    "            masked_region = masked_image[:, 128:132, 128:132, :]  # Input to GAN\n",
    "            original_region = original_image[:, 128:132, 128:132, :]  # True region to compare against\n",
    "\n",
    "            # GAN forward pass: reconstructing the masked region\n",
    "            gen_output = generator(masked_region)\n",
    "\n",
    "            # Discriminator: real and fake output\n",
    "            real_output = discriminator(original_region)\n",
    "            fake_output = discriminator(gen_output)\n",
    "\n",
    "            # GAN loss: Discriminator loss + Generator loss\n",
    "            gan_loss_real = tf.losses.binary_crossentropy(tf.ones_like(real_output), real_output)\n",
    "            gan_loss_fake = tf.losses.binary_crossentropy(tf.zeros_like(fake_output), fake_output)\n",
    "            gan_loss = gan_loss_real + gan_loss_fake\n",
    "\n",
    "            # Total loss (autoencoder + GAN)\n",
    "            total_loss = ae_loss + gan_loss\n",
    "\n",
    "        # Backpropagation: Compute gradients and apply to all models\n",
    "        gradients = tape.gradient(total_loss, autoencoder.trainable_variables + generator.trainable_variables + discriminator.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, autoencoder.trainable_variables + generator.trainable_variables + discriminator.trainable_variables))\n",
    "\n",
    "        # Print images and losses every 50 epochs\n",
    "        if epoch % 50 == 0:\n",
    "            print(f\"Epoch {epoch}: Autoencoder Loss: {ae_loss.numpy()}, GAN Loss: {gan_loss.numpy()}\")\n",
    "            display_images(original_image, masked_image, ae_output, masked_region, gen_output, epoch)\n",
    "\n",
    "        # Save models every 100 epochs\n",
    "        if epoch % save_interval == 0:\n",
    "            autoencoder.save(f\"models/autoencoder_{epoch}.h5\")\n",
    "            generator.save(f\"models/generator_{epoch}.h5\")\n",
    "            discriminator.save(f\"models/discriminator_{epoch}.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Masking function remains unchanged\n",
    "import matplotlib.pyplot as plt\n",
    "def mask_image(image, mask_size=4):\n",
    "    mask = np.ones(image.shape)\n",
    "    for i in range(0, image.shape[1], mask_size):\n",
    "        for j in range(0, image.shape[2], mask_size):\n",
    "            if np.random.rand() > 0.5:  # Randomly select blocks to mask\n",
    "                mask[:, i:i+mask_size, j:j+mask_size, :] = 0\n",
    "    return image * mask  # Return masked image\n",
    "def display_images(original_image, masked_image, gan_output, masked_region, ae_output, epoch):\n",
    "    fig, axs = plt.subplots(1, 5, figsize=(20, 5))\n",
    "    \n",
    "    # Original Image\n",
    "    axs[0].imshow(np.squeeze(original_image), cmap='gray')\n",
    "    axs[0].set_title('Original Image')\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    # Masked Input for GAN\n",
    "    axs[1].imshow(np.squeeze(masked_image), cmap='gray')\n",
    "    axs[1].set_title('Masked Input for GAN')\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    # GAN Output (Full Image Reconstruction)\n",
    "    axs[2].imshow(np.squeeze(gan_output), cmap='gray')\n",
    "    axs[2].set_title('GAN Output')\n",
    "    axs[2].axis('off')\n",
    "\n",
    "    # Masked Region Input for Autoencoder\n",
    "    axs[3].imshow(np.squeeze(masked_region), cmap='gray')\n",
    "    axs[3].set_title('Autoencoder Input (Masked Region)')\n",
    "    axs[3].axis('off')\n",
    "\n",
    "    # Autoencoder Output (Reconstructed Region)\n",
    "    axs[4].imshow(np.squeeze(ae_output), cmap='gray')\n",
    "    axs[4].set_title('Autoencoder Output')\n",
    "    axs[4].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "# Updated Training loop with swapped roles\n",
    "def train(autoencoder, generator, discriminator, image, epochs=1000, save_interval=100):\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "\n",
    "    # Store the original image for comparison\n",
    "    original_image = tf.convert_to_tensor(image)  # Assuming the image is loaded as a NumPy array\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Generate mask and apply to the image\n",
    "            masked_image = mask_image(image)\n",
    "\n",
    "            ### GAN now reconstructs the full image from the masked image ###\n",
    "            gan_output = generator(masked_image)\n",
    "\n",
    "            # GAN loss: comparing reconstructed full image with the original unmasked image\n",
    "            gan_loss = combined_loss(original_image, gan_output)  # SSIM + MSE with the original full image\n",
    "\n",
    "            ### Autoencoder now reconstructs the masked regions ###\n",
    "            masked_region = masked_image[:, 128:132, 128:132, :]  # Input to Autoencoder\n",
    "            original_region = original_image[:, 128:132, 128:132, :]  # True region to compare against\n",
    "\n",
    "            ae_output = autoencoder(masked_region)\n",
    "\n",
    "            # Autoencoder loss: comparing the reconstructed region with the original unmasked region\n",
    "            real_output = discriminator(original_region)\n",
    "            fake_output = discriminator(ae_output)\n",
    "\n",
    "            ae_loss_real = tf.losses.binary_crossentropy(tf.ones_like(real_output), real_output)\n",
    "            ae_loss_fake = tf.losses.binary_crossentropy(tf.zeros_like(fake_output), fake_output)\n",
    "            ae_loss = ae_loss_real + ae_loss_fake\n",
    "\n",
    "            # Total loss (GAN + Autoencoder)\n",
    "            total_loss = gan_loss + ae_loss\n",
    "\n",
    "        # Backpropagation: Compute gradients and apply to all models\n",
    "        gradients = tape.gradient(total_loss, generator.trainable_variables + autoencoder.trainable_variables + discriminator.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, generator.trainable_variables + autoencoder.trainable_variables + discriminator.trainable_variables))\n",
    "\n",
    "        # Print images and losses every 50 epochs\n",
    "        if epoch % 50 == 0:\n",
    "            print(f\"Epoch {epoch}: GAN Loss (Full Image): {gan_loss.numpy()}, Autoencoder Loss (Region): {ae_loss.numpy()}\")\n",
    "            display_images(original_image, masked_image, gan_output, masked_region, ae_output, epoch)\n",
    "\n",
    "        # Save models every 100 epochs\n",
    "        if epoch % save_interval == 0:\n",
    "            generator.save(f\"models/generator_{epoch}.h5\")\n",
    "            autoencoder.save(f\"models/autoencoder_{epoch}.h5\")\n",
    "            discriminator.save(f\"models/discriminator_{epoch}.h5\")\n",
    "\n",
    "image_path = '61_processed_image_edit.png'\n",
    "image = load_image(image_path)  # Define a function to load your image, e.g., using tf.keras.preprocessing.image.load_img\n",
    "image = image/255.0\n",
    "\n",
    "# Initialize the models\n",
    "autoencoder = build_autoencoder((4, 4, 1))  # Change according to your model design\n",
    "gan_generator = build_gan_generator((512, 512, 1))  # Change according to your model design\n",
    "discriminator = build_discriminator((4, 4, 1))  # Change according to your model design\n",
    "\n",
    "# Train the models\n",
    "train(autoencoder, gan_generator, discriminator, image, epochs=10000, save_interval=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to load and normalize the test images (infected brain and segmentation mask)\n",
    "def load_test_images(infected_image_path, segment_image_path):\n",
    "    # Load infected brain image and normalize it\n",
    "    infected_image = tf.keras.preprocessing.image.load_img(infected_image_path, color_mode='grayscale', target_size=(512, 512))\n",
    "    infected_image = np.array(infected_image).reshape(1, 512, 512, 1)\n",
    "    infected_image = infected_image / 255.0  # Normalize to [0, 1]\n",
    "\n",
    "    # Load segment mask (just for display, no processing)\n",
    "    segment_image = tf.keras.preprocessing.image.load_img(segment_image_path, color_mode='grayscale', target_size=(512, 512))\n",
    "    segment_image = np.array(segment_image).reshape(1, 512, 512, 1)\n",
    "\n",
    "    return infected_image, segment_image\n",
    "\n",
    "# Function to display the test results\n",
    "def display_test_results(original_image, segment_image, reconstructed_image, difference_image):\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "    # Display original infected brain image\n",
    "    axs[0].imshow(original_image.squeeze(), cmap='gray')\n",
    "    axs[0].set_title('Original Infected Brain Image')\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    # Display real segment mask\n",
    "    axs[1].imshow(segment_image.squeeze(), cmap='gray')\n",
    "    axs[1].set_title('Real Segment Mask')\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    # Display reconstructed clean brain image\n",
    "    axs[2].imshow(reconstructed_image.squeeze(), cmap='gray')\n",
    "    axs[2].set_title('Reconstructed Clean Brain Image')\n",
    "    axs[2].axis('off')\n",
    "\n",
    "    # Display difference image (original - reconstructed)\n",
    "    axs[3].imshow(difference_image.squeeze(), cmap='gray')\n",
    "    axs[3].set_title('Difference Image (Anomaly)')\n",
    "    axs[3].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Function for testing the complete model (Autoencoder + GAN)\n",
    "def test_model(generator, infected_image_path, segment_image_path):\n",
    "    # Load the test images\n",
    "    infected_image, real_segment = load_test_images(infected_image_path, segment_image_path)\n",
    "\n",
    "    # Step 1: Use the generator to reconstruct the clean brain image from the original infected image\n",
    "    reconstructed_image = generator.predict(infected_image)\n",
    "\n",
    "    # Step 2: Calculate the difference between the original infected image and the reconstructed clean image\n",
    "    difference_image = np.abs(infected_image - reconstructed_image)\n",
    "\n",
    "    # Step 3: Display the original, mask, reconstructed, and difference images\n",
    "    display_test_results(infected_image, real_segment, reconstructed_image, difference_image)\n",
    "\n",
    "# Paths to the test images (replace these paths with actual test image paths)\n",
    "infected_image_path = r\"C:\\Users\\priya\\Documents\\DL project\\test 2\\processed_image.png\"\n",
    "segment_image_path = r\"C:\\Users\\priya\\Documents\\DL project\\test 2\\processed_mask.png\"\n",
    "\n",
    "# Load the trained models\n",
    "generator = tf.keras.models.load_model('models/generator_9900.h5')  # Adjust path if needed\n",
    "\n",
    "# Run the test\n",
    "test_model(generator, infected_image_path, segment_image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to load and normalize the test images (infected brain)\n",
    "def load_test_images(infected_image_path):\n",
    "    infected_image = tf.keras.preprocessing.image.load_img(infected_image_path, color_mode='grayscale', target_size=(512, 512))\n",
    "    infected_image = np.array(infected_image).reshape(1, 512, 512, 1)\n",
    "    infected_image = infected_image / 255.0  # Normalize to [0, 1]\n",
    "    return infected_image\n",
    "\n",
    "# Function to predict the masked area using the autoencoder\n",
    "def predict_masked_area(autoencoder, image, window_size=4):\n",
    "    h, w = image.shape[1:3]\n",
    "    masked_output = np.zeros_like(image)\n",
    "\n",
    "    # Create a list to hold all windows for batch processing\n",
    "    windows = []\n",
    "    indices = []\n",
    "\n",
    "    for i in range(0, h, window_size):\n",
    "        for j in range(0, w, window_size):\n",
    "            # Define window boundaries\n",
    "            window = image[:, i:i + window_size, j:j + window_size, :]\n",
    "            windows.append(window)\n",
    "            indices.append((i, j))\n",
    "\n",
    "    # Convert list of windows to numpy array for batch processing\n",
    "    windows = np.concatenate(windows, axis=0)  # Shape: (number_of_windows, window_size, window_size, 1)\n",
    "    print(f\"Processing {windows.shape[0]} windows...\")\n",
    "\n",
    "    # Predict in batch\n",
    "    predicted_windows = autoencoder.predict(windows)\n",
    "\n",
    "    # Place predicted windows back into the masked output\n",
    "    for idx, (i, j) in enumerate(indices):\n",
    "        masked_output[:, i:i + window_size, j:j + window_size, :] = predicted_windows[idx]\n",
    "\n",
    "    return masked_output\n",
    "\n",
    "# Function to display the test results\n",
    "def display_test_results(original_image, autoencoder_output, gan_output, combined_image):\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(20, 5))\n",
    "\n",
    "    axs[0].imshow(original_image.squeeze(), cmap='gray')\n",
    "    axs[0].set_title('Original Infected Brain Image')\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    axs[1].imshow(autoencoder_output.squeeze(), cmap='gray')\n",
    "    axs[1].set_title('Autoencoder Output (Masked Area)')\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    axs[2].imshow(gan_output.squeeze(), cmap='gray')\n",
    "    axs[2].set_title('GAN Output (Clean Brain Image)')\n",
    "    axs[2].axis('off')\n",
    "\n",
    "    axs[3].imshow(combined_image.squeeze(), cmap='gray')\n",
    "    axs[3].set_title('Combined Image (Autoencoder + GAN)')\n",
    "    axs[3].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Function for testing the complete model (Autoencoder + GAN)\n",
    "def test_model(autoencoder, generator, infected_image_path):\n",
    "    # Load the test image\n",
    "    infected_image = load_test_images(infected_image_path)\n",
    "\n",
    "    # Step 1: Use the autoencoder to predict the masked area\n",
    "    autoencoder_output = predict_masked_area(autoencoder, infected_image)\n",
    "\n",
    "    # Step 2: Use the GAN to predict the clean brain image from the original infected image\n",
    "    gan_output = generator.predict(infected_image)\n",
    "\n",
    "    # Step 3: Combine the autoencoder output and GAN output\n",
    "    combined_image = autoencoder_output + gan_output  # Adjust as needed to combine images\n",
    "\n",
    "    # Step 4: Display the results\n",
    "    display_test_results(infected_image, autoencoder_output, gan_output, combined_image)\n",
    "\n",
    "# Paths to the test images (replace these paths with actual test image paths)\n",
    "infected_image_path = r\"C:\\Users\\priya\\Documents\\DL project\\test\\processed_image_edit.png\"\n",
    "\n",
    "# Load the trained models\n",
    "autoencoder = tf.keras.models.load_model('models/autoencoder_9900.h5')  # Adjust path if needed\n",
    "generator = tf.keras.models.load_model('models/generator_9900.h5')  # Adjust path if needed\n",
    "\n",
    "# Run the test\n",
    "test_model(autoencoder, generator, infected_image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
